\documentclass{yann}
\usepackage{dsfont}

\renewcommand{\T}{\mathscr{T}}
\newcommand{\Part}{\mathcal{P}}
\newcommand{\Pro}{\bigl(Î©,\T\bigr)}
\newcommand{\Prob}{\bigl(Î©,\T,â„™\bigr)}
\newcommand{\SEnsemble}[2]{\{ #1 \;|\; #2 \}}
\newcommand{\LProb}{\LL1\Prob}
\newcommand{\LL}[1]{\mathcal{L}^{#1}}
\newcommand{\Cov}{\mathop{\mathrm{Cov}}}
\newcommand{\me}{e}
\newcommand{\I}{i}

\begin{document}
\title{Variables alÃ©atoires discrÃ¨tes}
\maketitle

\Para{Notations}

Dans tout le chapitre
\begin{itemize}
\item
  $\Pro$ dÃ©signe un espace probabilisable;
\item
  $\Prob$ dÃ©signe un espace probabilisÃ©;
\item
  Toutes les variables alÃ©atoires considÃ©rÃ©es seront des variables alÃ©atoires \emph{discrÃ¨tes}.
\end{itemize}

% -----------------------------------------------------------------------------
\section{GÃ©nÃ©ralitÃ©s}

\subsection{Variables alÃ©atoires discrÃ¨tes}

\Para{DÃ©finition}

Une \emph{variable alÃ©atoire discrÃ¨te} $X$ sur $\Pro$ est une fonction $\Fn{X}{Î©}{E}$ telle que
\begin{itemize}
\item
  l'image $X(Î©)$ de $X$ est au plus dÃ©nombrable;
\item
  pour tout $xâˆˆX(Î©)$, l'ensemble $X^{-1}\bigl(\{ x \}\bigr)$ est un Ã©lÃ©ment de la tribu $\T$.
\end{itemize}

\Para{Lemme}

Dans ces conditions, pour toute partie $A$ de $E$, on a $X^{-1}(A)âˆˆ\T$.
On note \og{}$XâˆˆA$\fg{} l'Ã©vÃ©nement $X^{-1}(A)$.

\Para{DÃ©finition.}

Soit $X$ une variable alÃ©atoire sur $\Pro$.
On dit que \emph{$X$ est Ã  valeurs dans $F$} Â£ssi. $X(Î©)âŠ‚F$.

\subsection{Loi d'une variable alÃ©atoire discrÃ¨te}

\Para{DÃ©finition}

Soit $X$ une variable alÃ©atoire sur $\Prob$ Ã  valeurs dans $E$.
La \emph{loi} de $X$ est l'application
\[ \Fonction{â„™_X}{\Part(E)}{[0,1]}{A}{ â„™(XâˆˆA) = â„™\bigl(X^{-1}(A)\bigr) } \]
Il s'agit d'une probabilitÃ© sur l'espace probabilisable $\bigl(E,\Part(E)\bigr)$.

\Para{Proposition}

Soit $X$ une variable alÃ©atoire sur $\Prob$ Ã  valeurs dans $E$.
On suppose $E = \SEnsemble{x_n}{nâˆˆâ„•}$ oÃ¹ les $x_n$ sont deux Ã  deux distincts.
Alors la suite $p_n = â„™(X = x_n)$ caractÃ©rise la loi de la suite $â„™_X$.
Plus prÃ©cisÃ©ment, pour tout $AâŠ‚E$ on a
\[ â„™_X(A) = âˆ‘_{\substack{nâˆˆâ„•\\ x_nâˆˆA}} p_n \]

\Para{ThÃ©orÃ¨me d'existence}

Soit $X$ une variable alÃ©atoire sur $\Pro$ telle que
$X(Î©) = \SEnsemble{x_n}{nâˆˆâ„•}$ oÃ¹ les $x_n$ sont deux Ã  deux distincts.
Soit $(p_n)_{nâˆˆâ„•}$ une suite de rÃ©els positifs telle que la sÃ©rie $âˆ‘_n p_n$ converge et $âˆ‘_{nâ‰¥0} p_n = 1$.
Alors il existe une probabilitÃ© $â„™$ sur $\Pro$ telle que
\[ âˆ€nâˆˆâ„•\+â„™(X=x_n) = p_n. \]

\Para{Remarque}

Il n'y a pas unicitÃ© en gÃ©nÃ©ral.

\subsection{Fonction de rÃ©partition d'une variable alÃ©atoire rÃ©elle}

\Para{DÃ©finition}

Soit $X$ une variable alÃ©atoire rÃ©elle sur $\Prob$.
La \emph{fonction de rÃ©partition de $X$} est la fonction $\Fn{F_X}{â„}{â„}$ dÃ©finie par
\[ F_X(x) = â„™(Xâ‰¤x) = â„™_X(\intOF{-âˆ,x}). \]

\Para{PropriÃ©tÃ©s}

Soit $X$ une variable alÃ©atoire rÃ©elle sur $\Prob$
et $F_X$ sa fonction de rÃ©partition.
Alors, pour $(a,b) âˆˆâ„^2$, on a
\begin{enumerate}
\item
  $F_X$ est croissante sur $â„$;
\item
  $\DS \lim_{-âˆ} F_X = 0$;
\item
  $\DS \lim_{+âˆ} F_X = 1$;
\item
  Si $a < b$, alors $\DS â„™( a < X â‰¤b ) = F_X(b) - F_X(a)$;
\item
  $F_X$ est \emph{continue Ã  droite}, c.-Ã -d.
  $\DS\lim_{x\to a^+} F_X(x) = F_X(a)$;
\item
  $\DS \lim_{x \to a^-} F_X(x) = â„™(X < a)$;
\item
  $\DS â„™(X = a) = F_X(a) - \lim_{x \to a^-} F_X(x)$.
\end{enumerate}

\Para{ThÃ©orÃ¨me}

Soit $X$ et $Y$ deux variables alÃ©atoires rÃ©elles sur $\Prob$.
Alors $X$ et $Y$ ont la mÃªme fonction de rÃ©partition Â£ssi. $X$ et $Y$ ont mÃªme loi.
\[ F_X = F_Y \iff â„™_X = â„™_Y. \]

\subsection{Fonction d'une ou de plusieurs variables alÃ©atoires}

\Para{Lemme}

Soit $\Prob$ un espace probabilisÃ©, $\Fn{X}{Î©}{E}$ et $\Fn{Y}{Î©}{F}$ deux variables alÃ©atoires.
On pose $Z = (X,Y)$, c.-Ã -d.
\[ \Fonction{Z}{Î©}{EÃ—F}{Ï‰}{\bigl( X(Ï‰), Y(Ï‰) \bigr)} \]
Alors $Z$ est une variable alÃ©atoire discrÃ¨te Ã  valeurs dans $EÃ—F$.

Cela se gÃ©nÃ©ralise immÃ©diatement au cas de $n$ variables alÃ©atoires.

\Para{Proposition-DÃ©finition}

Soit $X$ une variable alÃ©atoire sur $\Pro$ Ã  valeurs dans $E$
et $\Fn{f}{E}{F}$ une application quelconque.
On note $f(X)$ la fonction $fâ—¦X$; il s'agit d'une variable alÃ©atoire discrÃ¨te.

\Para{Corollaire}

Soit $\Prob$ un espace probabilisÃ©.
On considÃ¨re $n$ variables alÃ©atoires discrÃ¨tes $\Fn{X_i}{Î©}{E_i}$ pour $iâˆˆ\Dcro{1,n}$.
Soit $\Fn{f}{âˆ_{i=1}^n E_i}{F}$ une application quelconque.
Alors $Y = f(X_1,X_2,\dots,X_n)$ est une variable alÃ©atoire discrÃ¨te.

% -----------------------------------------------------------------------------
\section{EspÃ©rance}

\subsection{Variables alÃ©atoires discrÃ¨tes d'espÃ©rances finies}

\Para{DÃ©finition}

Soit $X$ une variable alÃ©atoire rÃ©elle sur $\Prob$.
On suppose que $X(Î©)âŠ‚\SEnsemble{x_n}{nâˆˆâ„•}âŠ‚â„$ oÃ¹ les $x_n$ sont deux Ã  deux distincts.
On dit que $X$ est \emph{d'espÃ©rance finie} Â£ssi. la sÃ©rie $âˆ‘_n x_n \, â„™(X = x_n)$ converge absolument.
Quand c'est le cas, appelle espÃ©rance de $X$ le rÃ©el
\[ ğ”¼(X) = âˆ‘_{n=0}^{+âˆ} x_n \, â„™(X=x_n) \]

On admet que cette dÃ©finition ne dÃ©pend pas du choix de la suite $(x_n)_{nâˆˆâ„•}$.

\Para{Formule de transfert}

Soit $E = \SEnsemble{x_n}{nâˆˆâ„•}$ oÃ¹ les $x_n$ sont deux Ã  deux distincts.
Soit $X$ une variable alÃ©atoire Ã  valeurs dans $E$
et $\Fn{f}{E}{â„}$ une application quelconque.
Alors la variable alÃ©atoire $f(X)$ est d'espÃ©rance finie
Â£ssi. la sÃ©rie $âˆ‘_n f(x_n) \, â„™(X = x_n)$ converge absolument.
Dans ce cas, on a
\[ ğ”¼\bigl( f(X) \bigr) = âˆ‘_{n=0}^{+âˆ} f(x_n) \, â„™(X=x_n). \]

\Para{Proposition}[variables alÃ©atoires Ã©gales p.s.]

Soit $X$ et $Y$ deux variables alÃ©atoires discrÃ¨tes Ã  valeurs dans $E$.
On suppose que $X = Y$ presque sÃ»rement, Â£cad. que $â„™(X=Y) = 1$.
\begin{enumerate}
\item
  Dans le cas $E = â„$,
  $X$ est d'espÃ©rance finie Â£ssi. $Y$ l'est.
  Dans ce cas, on a $ğ”¼(X) = ğ”¼(Y)$.
\item
  Plus gÃ©nÃ©ralement, si $f$ est une fonction $E \to â„$,
  $f(X)$ est d'espÃ©rance finie Â£ssi. $f(Y)$ l'est.
  Dans ce cas, on a $ğ”¼(f(X)) = ğ”¼(f(Y))$.
\end{enumerate}

\Para{Proposition}

Soit $X$ et $Y$ deux variables alÃ©atoires rÃ©elles sur $\Prob$.
\begin{enumerate}
\item
  $X$ est d'espÃ©rance finie Â£ssi. $\Abs{X}$ est Ã©galement d'espÃ©rance finie.
\item
  Si $\Abs{X}â‰¤Y$ presque sÃ»rement, c.-Ã -d. si $â„™\bigl(\Abs{X}â‰¤Y\bigr) = 1$,
  et si $Y$ est d'espÃ©rance finie, alors $X$ est Ã©galement d'espÃ©rance finie.
\item
  En particulier, si $X$ est bornÃ©e, alors $X$ est d'espÃ©rance finie.
\item
  Si $X$ et $Y$ sont d'espÃ©rances finies, et $(Î»,Î¼)âˆˆâ„^2$,
  alors $Î»X+Î¼Y$ est Ã©galement d'espÃ©rance finie.
\end{enumerate}

\Para{Proposition}

Soit $X$ et $Y$ deux variables alÃ©atoires rÃ©elles
d'espÃ©rances finies sur $\Prob$.
On a
\begin{enumerate}
\item
  Si $Î»$ et $Î¼$ sont des rÃ©els, alors $ğ”¼(Î»X +Î¼Y) = Î»ğ”¼(X) + Î¼ğ”¼(Y)$.
\item
  Si $Xâ‰¥0$ presque sÃ»rement, alors $ğ”¼(X)â‰¥0$.
\item
  Si $Xâ‰¤Y$ presque sÃ»rement, alors $ğ”¼(X)â‰¤ğ”¼(Y)$.
\item
  Si $X = a$ presque sÃ»rement, alors $ğ”¼(X) = a$.
\item
  Si $ğ”¼\bigl( \Abs{X} \bigr) = 0$, alors $X = 0$ presque sÃ»rement.
\item
  Si $AâŠ‚â„$, alors $â„™(XâˆˆA) = ğ”¼\bigl( \mathds{1}_A(X) \bigr)$.
\item
  $\bigl| ğ”¼(X) \bigr| â‰¤ğ”¼\bigl( |X| \bigr)$.
\end{enumerate}

\Para{DÃ©finition}

Une variable alÃ©atoire rÃ©elle $X$ d'espÃ©rance finie est dite \emph{centrÃ©e} Â£ssi. $ğ”¼(X) = 0$.

\Para{Proposition}[inÃ©galitÃ© de Markov]

Soit $\Prob$ un espace probabilisÃ© et $X$ une variable alÃ©atoire discrÃ¨te d'espÃ©rance finie.
Si $X$ est Ã  valeurs dans $â„^+$ (presque sÃ»rement) et si $a > 0$, alors
\[ â„™(Xâ‰¥a) â‰¤ \frac{ğ”¼(X)}{a}. \]

\subsection{Moments d'une variable alÃ©atoire rÃ©elle}

\Para{DÃ©finition}

Soit $X$ une variable alÃ©atoire rÃ©elle sur $\Prob$.
Soit $pâˆˆâ„•$.
On dit que \emph{$X$ admet un moment d'ordre $p$} Â£ssi. la variable alÃ©atoire $X^p$ est d'espÃ©rance finie,
et on appelle \emph{moment d'ordre $p$ de $X$} le rÃ©el $ğ”¼(X^p)$.

On note $\LL p\Prob$ l'ensemble des variables alÃ©atoires rÃ©elles sur $\Prob$ qui admettent un moment d'ordre $p$.
On notera $\LL p$ au lieu de $\LL p\Prob$ lorsque le contexte le permettra.

\Para{Proposition}

Pour tout $pâˆˆâ„•$, $\LL p$ est un espace vectoriel.
De plus,
\begin{itemize}
\item
  $\LL0$ est l'ensemble des variables alÃ©atoires rÃ©elles discrÃ¨tes sur $\Pro$;
\item
  $\LL1$ est l'ensemble des variables alÃ©atoires rÃ©elles discrÃ¨tes sur $\Prob$ d'espÃ©rance finie.
\end{itemize}

\Para{Proposition}

Soit $(p,q)âˆˆâ„•^2$ tels que $pâ‰¤q$.
Alors $\LL q âŠ‚\LL p$.

\Para{Corollaire}

Soit $X$ une variable alÃ©atoire rÃ©elle. Si $X$ admet un moment d'ordre 2,
alors $X$ est d'espÃ©rance finie.

\Para{Proposition}

Si $X$ et $Y$ sont deux variables alÃ©atoires de $\LL2$,
alors $XYâˆˆ\LL1$.
De plus, on a l'inÃ©galitÃ© de Cauchy-Schwarz,
\[ ğ”¼(XY)^2 â‰¤ğ”¼(X^2) \,ğ”¼(Y^2). \]

\Para{DÃ©finition}

Soit $X$ une variable alÃ©atoire rÃ©elle d'espÃ©rance finie.
Notons $Y = \bigl(X -ğ”¼(X)\bigr)^2$.
Si $Y$ est d'espÃ©rance finie,
on dit que $X$ est \emph{de variance finie},
et on appelle \emph{variance de $X$} le rÃ©el $ğ”¼(Y)$.

\Para{Proposition}

Une variable alÃ©atoire rÃ©elle est de variance finie Â£ssi. elle est dans $\LL2$.

\Para{Proposition}

Soit $Xâˆˆ\LL2$.
\begin{enumerate}
\item
  \emph{Formule de KÃ¶nig-Huygens}: $ğ•(X) = ğ”¼(X^2) -ğ”¼(X)^2$.
\item
  Si $aâˆˆâ„$, alors $ğ•(aX) = a^2 ğ•(X)$ et $ğ•(X+a) = ğ•(X)$.
\item
  On a $ğ•(X) = 0$ Â£ssil. existe $aâˆˆâ„$ tel que $X = a$ presque sÃ»rement.
  Dans ce cas, $a = ğ”¼(X)$.
\end{enumerate}

\Para{InÃ©galitÃ© de BienaymÃ©-Tchebychev}

Soit $X$ une variable alÃ©atoire rÃ©elle de variance finie $Ïƒ^2$ et d'espÃ©rance $Î¼$.
Pour tout $Î±>0$, on a
\[ â„™ \bigPa{ \Abs{X-Î¼} â‰¥ Î± } â‰¤ \frac{Ïƒ^2}{Î±^2} \]

\subsection{Fonctions gÃ©nÃ©ratrices}

On s'intÃ©resse ici au cas des variables alÃ©atoires discrÃ¨tes Ã  valeurs dans $â„•$.

\Para{DÃ©finition}

Soit $X$ une variable alÃ©atoire rÃ©elle Ã  valeurs dans $â„•$.
On appelle \emph{fonction gÃ©nÃ©ratrice de $X$} la fonction $G_X$ dÃ©finie par
$G_X(t) = ğ”¼\bigl(t^X\bigr)$.

\Para{Proposition}

Avec les mÃªmes notations, posons $p_n = â„™(X=n)$. On a
\[ G_X(t) = âˆ‘_{n=0}^{+âˆ} p_n t^n. \]
$G_X$ est la somme d'une sÃ©rie entiÃ¨re.
De plus,
\begin{itemize}
\item
  son rayon de convergence $R_X$ vÃ©rifie $R_Xâ‰¥1$;
\item
  elle converge absolument sur $\intF{-1,1}$ (au moins);
\item
  elle est continue sur $\intF{-1,1}$;
\item
  elle est de classe $\CCâˆ$ sur $\intO{-R_X,R_X}$, et en particulier sur $\intO{-1,1}$.
\end{itemize}

\Para{Proposition}

Soit $X$ et $Y$ deux variables alÃ©atoires sur $\Prob$ Ã  valeurs dans $â„•$.
Alors $X$ et $Y$ ont la mÃªme f Â£ssi. $X$ et $Y$ ont la mÃªme loi.
\[ G_X = G_Y \iff â„™_X = â„™_Y. \]

\Para{ThÃ©orÃ¨me}

Soit $X$ une variable alÃ©atoire sur $\Prob$ Ã  valeurs dans $â„•$.
\begin{enumerate}
\item
  $X$ est d'espÃ©rance finie Â£ssi. $G_X$ est dÃ©rivable en $1$.
  Dans ce cas, $G_X'(1) = ğ”¼(X)$.
\item
  $X$ est de variance finie Â£ssi. $G_X$ est deux fois dÃ©rivable en $1$.
  Dans ce cas, on a $G_X''(1) =ğ”¼\bigl[ X(X-1) \bigr]$,
  de sorte que $ğ•(X) = G_X''(1) + G_X'(1) - G_X'(1)^2$.
  Il faut savoir retrouver cette derniÃ¨re formule.
\end{enumerate}

\Para{Remarque}

Si $X$ n'est pas Ã  valeurs dans $â„•$, la fonction gÃ©nÃ©ratrice $G_X$ n'est pas dÃ©finie.
On travaille gÃ©nÃ©ralement avec la \emph{fonction caractÃ©ristique}
$Ï†_X(t) = ğ”¼\bigl(\me^{\I t X}\bigr)$, qui est toujours dÃ©finie sur $â„$.

% -----------------------------------------------------------------------------
\section{Couples et suites de variables alÃ©atoires}

\subsection{Couples de variables alÃ©atoires}

\Para{DÃ©finition}

Soit $\Prob$ un espace probabilisÃ©,
$\Fn{X}{Î©}{E}$ et $\Fn{Y}{Î©}{F}$ deux variables alÃ©atoires discrÃ¨tes.
Notons $Z$ la variable alÃ©atoire discrÃ¨te $Z=(X,Y)$.
La loi de $Z$ s'appelle la \emph{loi conjointe} du couple $(X,Y)$,
et les lois de $X$ et de $Y$ s'appellent les \emph{lois marginales}.
Plus explicitement, notons $E = \SEnsemble{x_i}{iâˆˆâ„•}$ et $F = \SEnsemble{y_j}{jâˆˆâ„•}$.
\begin{itemize}
\item
  La loi conjointe du couple $(X,Y)$ est caractÃ©risÃ©e par
  la famille $(p_{i,j})_{(i,j)âˆˆâ„•^2}$ oÃ¹ $âˆ€(i,j)âˆˆâ„•^2$,
  \[ p_{i,j} = â„™\bigl(Z = (x_i,y_j)\bigr) = â„™( X = x_i, Y = y_j ) \]
\item
  La loi marginale de $X$ est caractÃ©risÃ©e par
  la famille $(q_i)_{iâˆˆâ„•}$ oÃ¹ $âˆ€iâˆˆâ„•$,
  \[ q_i = â„™(X = x_i) \]
\item
  La loi marginale de $Y$ est caractÃ©risÃ©e par
  la famille $(r_j)_{jâˆˆâ„•}$ oÃ¹ $âˆ€jâˆˆâ„•$,
  \[ r_j = â„™(Y = y_j) \]
\end{itemize}

\Para{Proposition}

Connaissant la loi conjointe d'un couple de variables alÃ©atoires,
on peut dÃ©terminer les lois marginales.
En effet, avec les mÃªmes notations, on a
\[ âˆ€iâˆˆâ„•\+ q_i = âˆ‘_{jâˆˆâ„•} p_{i,j} \quad \text{et}\quad âˆ€jâˆˆâ„•\+ r_j = âˆ‘_{iâˆˆâ„•} p_{i,j}. \]

Attention toutefois, il n'est pas possible de dÃ©terminer la loi conjointe Ã 
partir des lois marginales, sauf si l'on sait que $X$ et $Y$ sont indÃ©pendantes (voir ci-aprÃ¨s).

\subsection{IndÃ©pendance}

\Para{DÃ©finition}

Soit $\Fn{X}{Î©}{E}$ et $\Fn{Y}{Î©}{F}$ deux variables alÃ©atoires sur $\Prob$.
On dit que $X$ et $Y$ sont \emph{indÃ©pendantes} Â£ssi. $âˆ€(x,y)âˆˆEÃ—F$,
\[ â„™(X = x, Y = y) = â„™(X = x) \, â„™(Y = y). \]

\Para{Proposition}

Soit $\Fn{X}{Î©}{E}$ et $\Fn{Y}{Î©}{F}$ deux variables alÃ©atoires indÃ©pendantes sur $\Prob$.
Si $AâŠ‚E$ et $BâŠ‚F$, alors \[ â„™(XâˆˆA, YâˆˆB) = â„™(XâˆˆA) \, â„™(YâˆˆB). \]

\Para{Proposition}

Soit $\Prob$ un espace probabilisÃ©, $\Fn{X}{Î©}{E}$ et $\Fn{Y}{Î©}{F}$ deux variables alÃ©atoires discrÃ¨tes. Soit $\Fn{f}{E}{E'}$ et $\Fn{g}{F}{F'}$ deux fonctions quelconques.
Si $X$ et $Y$ sont indÃ©pendantes, alors les variables alÃ©atoires $f(X)$ et $g(Y)$ sont Ã©galement indÃ©pendantes.

\Para{Proposition}

Soit $Xâˆˆ\LL1$ et $Yâˆˆ\LL1$.
Si $X$ et $Y$ sont indÃ©pendantes, alors $XYâˆˆ\LL1$
et $ğ”¼(XY) = ğ”¼(X) \,ğ”¼(Y)$.

\Para{Corollaire}

Soit $X$ et $Y$ deux variables alÃ©atoires discrÃ¨tes Ã  valeurs dans $E$ et $F$ respectivement.
Soit $\Fn f Eâ„$ et $\Fn gFâ„$ deux fonctions quelconques.
Si $X$ et $Y$ sont indÃ©pendantes et si $f(X)$ et $g(Y)$ sont d'espÃ©rances finies,
alors $f(X)\, g(Y)$ est Ã©galement d'espÃ©rance finie et
\[ ğ”¼\bigPa{f(X)\,g(Y)} = ğ”¼\bigPa{f(X)} \, ğ”¼\bigPa{g(Y)}. \]

\Para{Proposition}[fonction gÃ©nÃ©ratrice de la somme de deux variables alÃ©atoires indÃ©pendantes]

Soit $\Prob$ un espace probabilisÃ©,
$X$ et $Y$ deux variables alÃ©atoires discrÃ¨tes Ã  valeurs dans $â„•$.
Notons $G_X$ (respectivement $G_Y$) la fonction gÃ©nÃ©ratrice de $X$ (resp. $Y$),
qui est absolument convergente sur $\mathcal{D}_X$ (resp. $\mathcal{D}_Y$)
et de rayon de convergence $R_X$ (resp. $R_Y$).
Si $X$ et $Y$ sont indÃ©pendantes, alors
\begin{itemize}
\item
  $\mathcal{D}_{X+Y} âŠƒ\mathcal{D}_X âˆ©\mathcal{D}_Y$,
\item
  $R_{X+Y} â‰¥\min(R_X, R_Y)$,
\item
  $âˆ€tâˆˆ\mathcal{D}_X âˆ©\mathcal{D}_Y$, on a $G_{X+Y} (t) = G_X(t) G_Y(t)$.
\end{itemize}

\Para{Exemple}

Utiliser ce rÃ©sultat pour montrer que si $X_1, \dots, X_n$ sont des variables (mutuellement) indÃ©pendantes qui suivent une loi de Bernoulli $\mathcal{B}(p)$, alors $S =âˆ‘_{k=1}^n X_k$ suit une loi binomiale $\mathcal{B}(n,p)$.

\subsection{Covariance, corrÃ©lation}

\Para{Proposition-DÃ©finitions}

Soit $X$ et $Y$ deux variables alÃ©atoires de $\LL2$ d'espÃ©rances $Î¼_X$ et $Î¼_Y$.
Alors la variable alÃ©atoire $(X - Î¼_X) (Y - Î¼_Y)$ est d'espÃ©rance finie.
On appelle \emph{covariance de $X$ et de $Y$} le rÃ©el
\[ \Cov(X,Y) = ğ”¼\bigl[ (X-Î¼_X)(Y-Î¼_Y) \bigr]. \]
On a Ã©galement
\[ \Cov(X,Y) = ğ”¼(XY) - Î¼_X Î¼_Y = ğ”¼(XY) - ğ”¼(X)ğ”¼(Y). \]

\Para{Proposition}

Soit $X$, $Y$ et $Z$ trois variables alÃ©atoires de $\LL2$
et $(a,b)âˆˆâ„^2$. On a
\begin{enumerate}
\item
  $\Cov(â‹…,â‹…)$ est une forme bilinÃ©aire symÃ©trique positive
  (mais non dÃ©finie positive) sur $\LL2$, c.-Ã -d.

  \begin{enumerate}
  \item
    $\Cov(aX+bY,Z) = a\Cov(X,Z) + b\Cov(Y,Z)$;
  \item
    $\Cov(X,aY+bZ) = a\Cov(X,Y) + b\Cov(X,Z)$;
  \item
    $\Cov(X,Y) = \Cov(Y,X)$;
  \item
    $\Cov(X,X) = ğ•(X)â‰¥0$.
  \end{enumerate}
\item
  $ğ•(aX+bY) = a^2ğ•(X) + b^2ğ•(Y) + 2ab \Cov(X,Y)$.
\item
  Si $X$ et $Y$ sont indÃ©pendantes, $\Cov(X,Y) = 0$.
\end{enumerate}

\Para{DÃ©finition}

Soit $X$ et $Y$ deux variables alÃ©atoires de $\LL2$ et de variances non nulles.
On appelle \emph{coefficient de corrÃ©lation linÃ©aire de $X$ et de $Y$} le rÃ©el
\[ Ï(X,Y) = \frac{\Cov(X,Y)}{âˆš{ğ•(X)ğ•(Y)}} \]

\Para{Proposition}

Dans ces conditions,
\begin{itemize}
\item
  $\Abs{Ï(X,Y)}â‰¤1$
\item
  $Ï(X,Y) = Â±1$ Â£ssil. existe $(a,b)âˆˆâ„^2$ tels que
  $Y = aX+b$ presque sÃ»rement.
\end{itemize}

\subsection{Suites de variables alÃ©atoires}

\Para{DÃ©finition}

Soit $X_1, \dots, X_n$ des variables alÃ©atoires sur $\Prob$, avec
$X_i$ Ã  valeurs dans $E_i$.
On dit que les variables $X_1, \dots, X_n$ sont \emph{mutuellement indÃ©pendantes}
Â£ssi. pour tous $(x_1, \dots, x_n) âˆˆâˆ_{i=1}^n E_i$, on a
\[ â„™(X_1 = x_1, X_2 = x_2, \dots, X_n = x_n) = âˆ_{i=1}^n â„™(X_i = x_i). \]

\Para{DÃ©finition}

Soit $(X_n)_{nâˆˆâ„•}$ une suite de variables alÃ©atoires.
On dit que les variables alÃ©atoires $(X_n)_{nâˆˆâ„•}$ sont \emph{mutuellement indÃ©pendantes} Â£ssi. pour tout $nâˆˆâ„•$, les variables alÃ©atoires $X_0, \dots, X_n$ sont mutuellement indÃ©pendantes.

\Para{Remarques}
\begin{itemize}
\item
  \og{}Mutuellement indÃ©pendantes\fg{} entraÃ®ne \og{}deux Ã  deux indÃ©pendantes\fg{}; \emph{la rÃ©ciproque est fausse}.
\item
  En l'absence de prÃ©cision, \og{}indÃ©pendantes\fg{} signifie \og{}mutuellement indÃ©pendantes\fg{}.
\end{itemize}

\Para{ThÃ©orÃ¨me d'existence}

Si on se donne pour chaque $nâˆˆâ„•$ une loi de probabilitÃ© discrÃ¨te $\mathcal{P}_n$ sur $â„$,
alors il existe un espace probabilisÃ© $\Prob$
et une suite de variables alÃ©atoires rÃ©elles discrÃ¨tes \emph{indÃ©pendantes} $(X_n)_{nâˆˆâ„•}$ telles que $X_n$ suit la loi $\mathcal{P}_n$ pour tout $n$.

Plus prÃ©cisÃ©ment,
soit $(x_{n,k})_{(n,k)âˆˆâ„•^2}$ et $(p_{n,k})_{(n,k)âˆˆâ„•^2}$ deux familles de rÃ©els telles que
\begin{itemize}
\item
  pour tout $nâˆˆâ„•$ fixÃ©, la suite $(x_{n,k})_{kâˆˆâ„•}$ soit injective;
\item
  pour tous $(n,k)âˆˆâ„•^2$, $p_{n,k}â‰¥0$;
\item
  pour tout $nâˆˆâ„•$, la sÃ©rie $âˆ‘_k p_{n,k}$ converge et $âˆ‘_{k=0}^{+âˆ} p_{n,k} = 1$.
\end{itemize}

Pour $nâˆˆâ„•$, on pose $E_n = \SEnsemble{x_{n,k}}{kâˆˆâ„•}$.
Alors il existe un espace probabilisÃ© $\Prob$
et une suite de variables alÃ©atoires rÃ©elles discrÃ¨tes $(X_n)_{nâˆˆâ„•}$ sur $\Pro$ telles que:
\begin{itemize}
\item
  les variables alÃ©atoires $(X_n)_{nâˆˆâ„•}$ sont indÃ©pendantes;
\item
  pour tout $nâˆˆâ„•$, la variable alÃ©atoire $X_n$ est Ã  valeurs dans $E_n$
  et sa loi est dÃ©finie par
  \[ âˆ€kâˆˆâ„•\+â„™(X_n = x_{n,k}) = p_{n,k}. \]
\end{itemize}

\Para{Remarque}

En gÃ©nÃ©ral, $Î©$ n'est pas dÃ©nombrable et $\Tâ‰ \Part(Î©)$.

\subsection{RÃ©sultats asymptotiques}

\Para{ThÃ©orÃ¨me}[approximation de la loi binomiale par une loi de Poisson]

Soit $(p_n)_{nâˆˆâ„•}$ une suite numÃ©rique Ã  valeurs dans $[0,1]$.
Soit $(X_n)_{nâˆˆâ„•}$ une suite de variables alÃ©atoires rÃ©elles
de loi binomiale $\mathcal{B}(n,p_n)$.
Si $np_n \ToninfÎ»âˆˆâ„$, alors
\[ â„™(X_n = k) \Toninf \frac{\me^{-Î»} Î»^k}{k!}. \]

\Para{ThÃ©orÃ¨me}[loi faible des grands nombres]

Soit $(X_n)_{nâ‰¥1}$ une suite de variables alÃ©atoires rÃ©elles
deux Ã  deux indÃ©pendantes, de mÃªme loi et admettant un moment d'ordre 2.
Notons $Î¼= ğ”¼(X_1)$ et
$S_n = âˆ‘_{k=1}^n X_k$.
Alors
\[ â„™\left( \left| \frac{S_n}{n} - Î¼\right| â‰¥Îµ\right) \Toninf 0. \]

\Para{Remarques}
\begin{itemize}
\item
  La quantitÃ© $\frac{S_n}{n}$ s'appelle la \emph{moyenne empirique} de $(X_n)_{nâ‰¥1}$.
\item
  Le rÃ©sultat prÃ©cÃ©dent reste vrai si l'on remplace l'hypothÃ¨se \og{}admettre un moment d'ordre 2\fg{}
  par l'hypothÃ¨se plus faible \og{}Ãªtre d'espÃ©rance finie\fg{}.
\end{itemize}

% -----------------------------------------------------------------------------
\section{Lois usuelles}

\subsection{Lois finies}

\Para{Loi uniforme}

On dit que $X$ suit la loi uniforme sur l'ensemble fini $F$,
et on note $Xâ†ª\mathcal{U}(F)$
si $X$ est une variable alÃ©atoire discrÃ¨te Ã  valeurs dans $F$ telle que
\[ âˆ€xâˆˆF \+ â„™(X=x) = \frac{1}{\Card(F)}. \]
Par exemple, si $F = \Dcro{1,n}$, alors:
\[ ğ”¼(X) = \frac{n+1}{2}, \quad ğ•(X) = \frac{n^2-1}{12}, \quad G_X(t) = \frac{t(1-t^n)}{n(1-t)}. \]

\Para{Loi de Bernoulli}

On dit que $X$ suit la loi de Bernoulli de paramÃ¨tre $pâˆˆ[0,1]$,
et on note $Xâ†ª\mathcal{B}(p)$
si $X$ est une variable alÃ©atoire discrÃ¨te Ã  valeurs dans $\{0,1\}$ telle que
\[ â„™(X=0) = q, \quad â„™(X=1) = p, \quad \text{oÃ¹ } q = 1-p. \]
\[ ğ”¼(X) = p, \quad ğ•(X) = pq, \quad G_X(t) = q + pt. \]

\Para{Loi binomiale}

On dit que $X$ suit la loi binomiale de paramÃ¨tres $nâˆˆâ„•$ et $pâˆˆ[0,1]$,
et on note $Xâ†ª\mathcal{B}(n,p)$
si $X$ est une variable alÃ©atoire discrÃ¨te Ã  valeurs dans $\Dcro{0,n}$ telle que
\[ âˆ€kâˆˆ\Dcro{0,n} \+ â„™(X=k) = \binom{n}{k} p^k q^{n-k},
\quad \text{oÃ¹ } q = 1-p. \]
\[ ğ”¼(X) = np, \quad ğ•(X) = npq, \quad G_X(t) = (q + pt)^n. \]

\subsection{Lois discrÃ¨tes}

\Para{Loi gÃ©omÃ©trique}

On dit que $X$ suit la loi gÃ©omÃ©trique de paramÃ¨tre $pâˆˆ\intO{0,1}$,
et on note $Xâ†ª\mathcal{G}(p)$
si $X$ est une variable alÃ©atoire discrÃ¨te Ã  valeurs dans $â„•^*$ telle que
\[ âˆ€kâˆˆâ„•^* \+ â„™(X=k) = q^{k-1} p,
\quad \text{oÃ¹ } q = 1-p. \]
\[ ğ”¼(X) = \frac{1}{p}, \quad ğ•(X) = \frac{q}{p^2}, \quad G_X(t) = \frac{pt}{1-qt}. \]

\Para{Loi de Poisson}

On dit que $X$ suit la loi de Poisson de paramÃ¨tre $Î»âˆˆâ„^+$,
et on note $Xâ†ª\mathcal{P}(Î»)$
si $X$ est une variable alÃ©atoire discrÃ¨te Ã  valeurs dans $â„•$ telle que
\[ âˆ€kâˆˆâ„•\+ â„™(X=k) = \frac{\me^{-Î»} Î»^k}{k!}. \]
\[ ğ”¼(X) = Î», \quad ğ•(X) = Î», \quad G_X(t) = \me^{Î»(t-1)}. \]

% -----------------------------------------------------------------------------
\section{Exercices}

\Exercice

DÃ©montrer les formules de la partie \og{}lois usuelles\fg{}.

\Exercice[paradoxe de St Petersbourg]

Une banque vous propose de jouer au jeu suivant:
votre mise est de 100â‚¬.
Ensuite, vous lancez une piÃ¨ce Ã©quilibrÃ©e jusqu'Ã  ce que vous obteniez \og{}pile\fg{}
On note $X$ le nombre de lancÃ©s nÃ©cessaires.
Votre gain est de $G = 2^X$.
\begin{enumerate}
\item
  \begin{enumerate}
  \item
    Montrer que $X$ est Ã  valeurs dans $â„•^*âˆª\{+âˆ\}$.
  \item
    Calculer $â„™(X = +âˆ)$.
  \item
    ReconnaÃ®tre la loi de $X$.
  \end{enumerate}
\item
  Calculer $ğ”¼(G)$. Devriez-vous jouer Ã  ce jeu?
\item
  En fait, si $G$ est trop Ã©levÃ©, la banque fera faillite.
  D'aprÃ¨s Wikipedia, le PIB mondial pour 2013 est environ $73~\mathrm{TUS\$}$ (Wikipedia).
  On note $H = \min(G,2^{50})$ le gain corrigÃ©.
  DÃ©terminer l'espÃ©rance de $H$.
  Devriez-vous jouer Ã  ce jeu?
\end{enumerate}

\Exercice

Environ $5\%$ des rÃ©servations aÃ©riennes sur une ligne donnÃ©e ne sont
pas utilisÃ©es, et c'est pourquoi une compagnie vend 100 billets pour
97 places; on parle de \og{}surbooking\fg{}.
Quelle est la probabilitÃ© pour que tous les passagers aient une place?

\Exercice[loi de Pascal]

Soit $(X_n)_{nâˆˆâ„•^*}$ une suite de variables alÃ©atoires indÃ©pendantes
suivant une loi de Bernoulli $\mathcal{B}(p)$ avec $pâˆˆ\intOF{0,1}$.
Soit $kâˆˆâ„•$ fixÃ©.
On note $T = \min \Ensemble{nâˆˆâ„•}{X_1 + \dots + X_n = k}âˆˆâ„•âˆª\acco{âˆ}$.
\begin{enumerate}
\item
  DÃ©crire en franÃ§ais ce que reprÃ©sente $T$.
\item
  Montrer que $T<âˆ$ presque sÃ»rement.
  On pourra introduire $S_n = X_1 + \dots + X_n$
  et utiliser la loi des grands nombres pour montrer que
  $â„™\bigPa{\frac{S_n}{n} â‰¤\frac{p}{2}} \to 0$ quand $n\to+âˆ$.
\item
  DÃ©terminer la loi de $T$.
  On dit que $T$ suit la loi de Pascal de paramÃ¨tres $k$ et $p$.
\item
  DÃ©terminer l'espÃ©rance, la variance de $T$
  et la fonction gÃ©nÃ©ratrice de $T$.
\item
  Soit $U = Y_1 + \dots + Y_k$ oÃ¹ $Y_iâ†ª\mathcal{G}(p)$.
  Montrer que $T$ et $U$ ont la mÃªme loi.
\end{enumerate}

\Exercice

Soit $(X_{i,j})_{1â‰¤i,jâ‰¤n}$ une famille de variables alÃ©atoires indÃ©pendantes de mÃªme loi telles que $P(X_{i,j} = 1) = â„™(X_{i,j} = -1) = \frac12$.
On note $M$ la matrice dont les coefficients sont les $(X_{i,j})$.
Quelle est l'espÃ©rance du dÃ©terminant de $M$?

\Exercice

On considÃ¨re une expÃ©rience alÃ©atoire ayant une probabilitÃ© $p$ de rÃ©ussir et $1-p$ d'Ã©chouer.
On rÃ©pÃ¨te l'expÃ©rience de faÃ§on indÃ©pendante jusqu'Ã  obtention de $n$ succÃ¨s.
On note $X$ le nombre d'essais nÃ©cessaires Ã  l'obtention de ces $n$ succÃ¨s.
\begin{enumerate}
\item
  ReconnaÃ®tre la loi de $X$ lorsque $n=1$.
\item
  DÃ©terminer la loi de $X$ dans le cas gÃ©nÃ©ral.
\item
  Exprimer le dÃ©veloppement en sÃ©rie entiÃ¨re de
  $(1-t)^{-n-1}$.
\item
  DÃ©terminer la fonction gÃ©nÃ©ratrice de $X$
  et en dÃ©duire l'espÃ©rance de $X$.
\end{enumerate}

\Exercice
\begin{enumerate}
\item
  Soit $Xâ†ª\mathcal{P}(Î»)$.
  Montrer que l'Ã©vÃ©nement \og{}$X$ est pair\fg{} est plus probable que l'Ã©vÃ©nement \og{}$X$ est impair\fg{}.
\item
  MÃªme question avec $Xâ†ª\mathcal{G}(p)$.
\end{enumerate}

\Exercice

Soit $Xâ†ª\mathcal{P}(Î»)$ et $Yâ†ª\mathcal{P}(Î¼)$ deux variables alÃ©atoires indÃ©pendantes.
Quelle est la loi de $X+Y$?

\Exercice

Le jour de l'examen de fin d'annÃ©e, $n$ Ã©lÃ¨ves n'ont pas assez soignÃ© la prÃ©sentation de leur copie.
Le correcteur, plutÃ´t que de s'escrimer Ã  lire d'infÃ¢mes brouillons, dÃ©cide de noter au hasard, de maniÃ¨re indÃ©pendante, les $n$ copies, en leur attribuant une note entiÃ¨re, au hasard, entre 0 et 20.
On note $X_n$ la variable alÃ©atoire Ã©gale Ã  la meilleure note du groupe.
\begin{enumerate}
\item
  Soit $kâˆˆ\Dcro{0,20}$.
  Calculer la probabilitÃ© que toutes les notes soient infÃ©rieures ou Ã©gales Ã  $k$.
\item
  \begin{enumerate}
  \item
    Calculer $â„™(X_n < k \mid X_nâ‰¤k)$.
  \item
    En dÃ©duire $â„™( X_n = k \mid X_nâ‰¤k)$.
  \end{enumerate}
\item
  Calculer $â„™(X_n = k)$ et dÃ©terminer sa limite lorsque $n \toâˆ$.
  InterprÃ©ter.
\end{enumerate}

\Exercice[lois sans viellissement]

Soit $X$ une variable alÃ©atorie Ã  valeurs dans $â„•^*$,
telle que $âˆ€nâˆˆâ„•^*$, $â„™(X=n) > 0$.
On suppose de plus que pour tous $(n,p)âˆˆâ„•^2$,
\[ â„™(X > n+p \;|\; X > p) = â„™(X > n). \]
Montrer que $X$ suit une loi gÃ©omÃ©trique.

\Exercice

Expliquer pourquoi $99,\!9\,\%$ des gens possÃ¨dent un nombre de jambes strictement supÃ©rieur Ã  la moyenne.

\Exercice

Soit $Xâ†ª\mathcal{G}(p)$.
On pose $Y = 1/X$. Calculer $ğ”¼(Y)$.

\Exercice[Ã  connaÃ®tre]

Soit $X$ une variable alÃ©atoire Ã  valeurs dans $â„•$.
\begin{enumerate}
\item
  \begin{enumerate}
  \item
    Montrer que que $â„™(X = n) = â„™(X > n-1) - â„™(X > n)$ pour tout $nâˆˆâ„•^*$.
  \item
    Si $Xâˆˆ\LL1$, montrer que $nâ„™(X>n) \Toninf 0$.
  \item
    Si $Xâˆˆ\LL1$, montrer que \[ ğ”¼(X) = âˆ‘_{nâ‰¥0} â„™(X > n). \]
  \item
    Si $Xâˆ‰\LL1$, montrer que la sÃ©rie $âˆ‘_n â„™(X>n)$ diverge.
  \end{enumerate}
\item
  Si $Xâˆˆ\LL2$, montrer de mÃªme que
  \[ ğ”¼(X^2) = âˆ‘_{nâ‰¥0} (2n+1) \, â„™(X > n). \]
\end{enumerate}

\Exercice

Soit $Xâ†ª\mathcal{P}(Î»)$.
Montrer que $â„™\bigl(Xâ‰¤\fracÎ»2\bigr)â‰¤\frac4Î»$
et $â„™\bigl(Xâ‰¥2Î»\bigr)â‰¤\frac1Î»$.

\Exercice

Soit $X$ et $Y$ deux variables alÃ©atoires de lois de Bernoulli respectives $\mathcal{B}(p)$ et $\mathcal{B}(p')$.
Montrer qu'elles sont indÃ©pendantes Â£ssi. $\Cov(X,Y) = 0$.

\Exercice

Soit $X$ une variable alÃ©atoire discrÃ¨te Ã  valeurs dans $E$
et $\Fn{f}{E}{F}$ une application.
Ã€ quelle condition les variables alÃ©atoires $X$ et $f(X)$ sont-elles indÃ©pendantes?

\Exercice

Soit $X_1, \dots, X_n$ des variables alÃ©atoires indÃ©pendantes Ã  valeurs dans $â„•$.
On pose $Y = Î±_1 X_1 + \dots + Î±_n X_n$ oÃ¹ $\nUpletÎ±1n âˆˆâ„•^n$.
Exprimer la sÃ©rie gÃ©nÃ©ratrice $G_Y$ en fonction des $G_{X_i}$.

\Exercice

On considÃ¨re une succession (infine) de tirages Ã  \og{}pile ou face\fg{}, avec une piÃ¨ce donnant \og{}pile\fg{} avce une probabilitÃ© $pâˆˆ\intO{0,1}$.
On note $N$ le nombre de tirages nÃ©cessaires pour avoir le premier \og{}pile\fg{}.
On effectue alors $N$ nouveaux tirages, et l'on note $X$ le nombre de \og{}pile\fg{} obtenus pendant ces nouveaux tirages.
Montrer que $ğ”¼(X) = 1$.

\Exercice[loi binomiale et loi de Poisson]

Soit $(X_n)$ une suite de variables alÃ©atoires telles que $X_nâ†ª\mathscr{B}(n,p_n)$
avec $p_n = \frac{Î»}{n}$.
\begin{enumerate}
\item
  DÃ©terminer la limite de $ğ”¼(X_n)$ et de $ğ•(X_n)$.
\item
  DÃ©terminer la limite de $â„™(X_n = k)$ quand $n\to+âˆ$.
\item
  Comment interprÃ©ter ces rÃ©sultats?
\end{enumerate}

\Exercice

Dans une grande ville, il y a en moyenne un suicide par jour.
Combien y a-t-il, en moyenne, de jours de l'annÃ©e oÃ¹ au moins $5$ personnes
se suicident?

\Exercice

Tous les soirs, au lieu de rÃ©viser ses cours de prÃ©pa, Kevin va rusher Stratholme
dans l'espoir de looter la monture du Baron Vaillefendre.
\begin{enumerate}
\item
  Ã‰tant donnÃ© que WoW est un programme informatique (considÃ©rÃ© comme constant),
  par quelle loi modÃ©liseriez-vous cette expÃ©rience?
\item
  Il semblerait que la probabilitÃ© de dropper la monture soit de $0,7\%$.
  Au bout de combien de jours Kevin peut-il espÃ©rer frimer sur le destrier de la mort?
  Au fait, d'oÃ¹ peut provenir ce chiffre de $0,7\%$?
\item
  Quelle est la probabilitÃ© d'arriver Ã  la dropper en moins de 210 jours
  (entre le dÃ©but et la fin des cours)?
  On pourra utiliser la calculatrice, ou l'approximation par une loi de Poisson.
\item
  Question subsidiaire: que pensez-vous des chances de rÃ©ussite aux concours de Kevin?
\end{enumerate}

\Exercice[moindres carrÃ©s]
\begin{enumerate}
\item
  Soit $Xâˆˆ\LL2$.
  Quelle valeur de $aâˆˆâ„$ minimise-t-elle la quantitÃ©
  $ğ”¼\bigl[ (X-a)^2 \bigr]$?
\item
  Soit $X$ et $Y$ deux variables alÃ©atoires de $\LL2$.
  DÃ©terminer $(a,b)âˆˆâ„^2$ qui minimise
  $ğ”¼\bigl[ (Y - aX-b)^2 \bigr]$.
\end{enumerate}

\Exercice

Soit $X$ et $Y$ deux variables alÃ©atoires Ã  valeurs dans $â„•$ de loi conjointe
\[ âˆ€(i,j)âˆˆâ„•^2 \+ â„™(X = i, Y = j) = \frac{a}{i!j!}. \]
\begin{enumerate}
\item
  DÃ©terminer $a$.
\item
  ReconnaÃ®tre les lois marginales de $X$ et de $Y$.
\item
  $X$ et $Y$ sont-elles indÃ©pendantes?
\end{enumerate}

\Exercice[inÃ©galitÃ© de Jensen]

Soit $I$ un intervalle de $â„$, $\Fn{f}{I}{â„}$ une fonction convexe et
$X$ une variable alÃ©atoire rÃ©elle Ã  valeurs dans $I$ d'espÃ©rance finie.
L'inÃ©galitÃ© de Jensen affirme alors que, si $f(X)$ est d'espÃ©rance finie, on a
\[ ğ”¼\bigl(f(X)\bigr)â‰¥f\bigl(ğ”¼(X) \bigr). \]
\begin{enumerate}
\item
  On suppose $f$ dÃ©rivable sur $I$.

  \begin{enumerate}
  \item
    Soit $Î¼âˆˆI$. Montrer qu'il existe $(a,b)âˆˆâ„^2$ tels que
    $âˆ€xâˆˆI$, $f(x)â‰¥ax+b$ et $f(Î¼) = aÎ¼+ b$.
  \item
    Montrer que $ğ”¼(X)âˆˆI$.
  \item
    Conclure.
  \end{enumerate}
\item
  (dur) Montrer que le rÃ©sultat de la question 1a. reste vrai
  si l'on ne suppose plus $f$ dÃ©rivable. Conclure.
\end{enumerate}

\Exercice[identitÃ© de Wald]

Soit $N$ et $(X_n)_{nâ‰¥1}$ des variables alÃ©atoires indÃ©pendantes Ã  valeurs dans $â„•$ et d'espÃ©rances finies.
On suppose que les $(X_n)_{nâ‰¥1}$ ont toutes la mÃªme loi.
On pose \[ S = âˆ‘_{k=1}^N X_k. \]
\begin{enumerate}
\item
  Montrer que $G_S(t) = G_N\bigl( G_{X_1}(t) \bigr)$ pour $\Abs{t}<1$.
  On admettra que l'on peut permuter les sommes.
\item
  Ã‰tablir l'\emph{identitÃ© de Wald}:
  \[ ğ”¼(S) = ğ”¼(N) \, ğ”¼(X_1). \]
\end{enumerate}

\end{document}
