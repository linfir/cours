% autogenerated by ytex.rs

\documentclass{scrartcl}

\usepackage[francais]{babel}
\usepackage{geometry}
\usepackage{scrpage2}
\usepackage{lastpage}
\usepackage{ragged2e}
\usepackage{multicol}
\usepackage{etoolbox}
\usepackage{xparse}
\usepackage{enumitem}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{stmaryrd}
\usepackage{dsfont}
\usepackage{eurosym}
\usepackage{numprint}
\usepackage[most]{tcolorbox}
\usepackage{tikz}
\usepackage{tkz-tab}
\usepackage[unicode]{hyperref}
\usepackage[ocgcolorlinks]{ocgx2}

\let\ifTwoColumns\iftrue
\def\Classe{$\Psi$2019--2020}

% reproducible builds
% LuaTeX: \pdfvariable suppressoptionalinfo 1023 \relax
\pdfinfoomitdate=1
\pdftrailerid{}

\newif\ifDisplaystyle
\everymath\expandafter{\the\everymath\ifDisplaystyle\displaystyle\fi}
\newcommand\DS{\displaystyle}

\clearscrheadfoot
\pagestyle{scrheadings}
\thispagestyle{empty}
\ohead{\Classe}
\ihead{\thepage/\pageref*{LastPage}}

\setlist[itemize,1]{label=\textbullet}
\setlist[itemize,2]{label=\textbullet}

\ifTwoColumns
  \geometry{margin=1cm,top=2cm,bottom=3cm,foot=1cm}
  \setlist[enumerate]{leftmargin=*}
  \setlist[itemize]{leftmargin=*}
\else
  \geometry{margin=3cm}
\fi

\makeatletter
\let\@author=\relax
\let\@date=\relax
\renewcommand\maketitle{%
    \begin{center}%
        {\sffamily\huge\bfseries\@title}%
        \ifx\@author\relax\else\par\medskip{\itshape\Large\@author}\fi
        \ifx\@date\relax\else\par\bigskip{\large\@date}\fi
    \end{center}\bigskip
    \ifTwoColumns
        \par\begin{multicols*}{2}%
        \AtEndDocument{\end{multicols*}}%
        \setlength{\columnsep}{5mm}
    \fi
}
\makeatother

\newcounter{ParaNum}
\NewDocumentCommand\Para{smo}{%
  \IfBooleanF{#1}{\refstepcounter{ParaNum}}%
  \paragraph{\IfBooleanF{#1}{{\tiny\arabic{ParaNum}~}}#2\IfNoValueF{#3}{ (#3)}}}

\newcommand\I{i}
\newcommand\mi{i}
\def\me{e}

\def\do#1{\expandafter\undef\csname #1\endcsname}
\docsvlist{Ker,sec,csc,cot,sinh,cosh,tanh,coth,th}
\undef\do

\DeclareMathOperator\ch{ch}
\DeclareMathOperator\sh{sh}
\DeclareMathOperator\th{th}
\DeclareMathOperator\coth{coth}
\DeclareMathOperator\cotan{cotan}
\DeclareMathOperator\argch{argch}
\DeclareMathOperator\argsh{argsh}
\DeclareMathOperator\argth{argth}

\let\epsilon=\varepsilon
\let\phi=\varphi
\let\leq=\leqslant
\let\geq=\geqslant
\let\subsetneq=\varsubsetneq
\let\emptyset=\varnothing

\newcommand{\+}{,\;}

\undef\C
\newcommand\ninf{{n\infty}}
\newcommand\N{\mathbb{N}}
\newcommand\Z{\mathbb{Z}}
\newcommand\Q{\mathbb{Q}}
\newcommand\R{\mathbb{R}}
\newcommand\C{\mathbb{C}}
\newcommand\K{\mathbb{K}}
\newcommand\Ns{\N^*}
\newcommand\Zs{\Z^*}
\newcommand\Qs{\Q^*}
\newcommand\Rs{\R^*}
\newcommand\Cs{\C^*}
\newcommand\Ks{\K^*}
\newcommand\Rp{\R^+}
\newcommand\Rps{\R^+_*}
\newcommand\Rms{\R^-_*}
\newcommand{\Rpinf}{\Rp\cup\Acco{+\infty}}

\undef\B
\newcommand\B{\mathscr{B}}

\undef\P
\DeclareMathOperator\P{\mathbb{P}}
\DeclareMathOperator\E{\mathbb{E}}
\DeclareMathOperator\Var{\mathbb{V}}

\DeclareMathOperator*\PetitO{o}
\DeclareMathOperator*\GrandO{O}
\DeclareMathOperator*\Sim{\sim}
\DeclareMathOperator\Tr{tr}
\DeclareMathOperator\Ima{Im}
\DeclareMathOperator\Ker{Ker}
\DeclareMathOperator\Sp{Sp}
\DeclareMathOperator\Diag{diag}
\DeclareMathOperator\Rang{rang}
\DeclareMathOperator*\Coords{Coords}
\DeclareMathOperator*\Mat{Mat}
\DeclareMathOperator\Pass{Pass}
\DeclareMathOperator\Com{Com}
\DeclareMathOperator\Card{Card}
\DeclareMathOperator\Racines{Racines}
\DeclareMathOperator\Vect{Vect}
\DeclareMathOperator\Id{Id}

\newcommand\DerPart[2]{\frac{\partial #1}{\partial #2}}

\def\T#1{{#1}^T}

\def\pa#1{({#1})}
\def\Pa#1{\left({#1}\right)}
\def\bigPa#1{\bigl({#1}\bigr)}
\def\BigPa#1{\Bigl({#1}\Bigr)}
\def\biggPa#1{\biggl({#1}\biggr)}
\def\BiggPa#1{\Biggl({#1}\Biggr)}

\def\pafrac#1#2{\pa{\frac{#1}{#2}}}
\def\Pafrac#1#2{\Pa{\frac{#1}{#2}}}
\def\bigPafrac#1#2{\bigPa{\frac{#1}{#2}}}
\def\BigPafrac#1#2{\BigPa{\frac{#1}{#2}}}
\def\biggPafrac#1#2{\biggPa{\frac{#1}{#2}}}
\def\BiggPafrac#1#2{\BiggPa{\frac{#1}{#2}}}

\def\cro#1{[{#1}]}
\def\Cro#1{\left[{#1}\right]}
\def\bigCro#1{\bigl[{#1}\bigr]}
\def\BigCro#1{\Bigl[{#1}\Bigr]}
\def\biggCro#1{\biggl[{#1}\biggr]}
\def\BiggCro#1{\Biggl[{#1}\Biggr]}

\def\abs#1{\mathopen|{#1}\mathclose|}
\def\Abs#1{\left|{#1}\right|}
\def\bigAbs#1{\bigl|{#1}\bigr|}
\def\BigAbs#1{\Bigl|{#1}\Bigr|}
\def\biggAbs#1{\biggl|{#1}\biggr|}
\def\BiggAbs#1{\Biggl|{#1}\Biggr|}

\def\acco#1{\{{#1}\}}
\def\Acco#1{\left\{{#1}\right\}}
\def\bigAcco#1{\bigl\{{#1}\bigr\}}
\def\BigAcco#1{\Bigl\{{#1}\Bigr\}}
\def\biggAcco#1{\biggl\{{#1}\biggr\}}
\def\BiggAcco#1{\Biggl\{{#1}\Biggr\}}

\def\ccro#1{\llbracket{#1}\rrbracket}
\def\Dcro#1{\llbracket{#1}\rrbracket}

\def\floor#1{\lfloor#1\rfloor}
\def\Floor#1{\left\lfloor{#1}\right\rfloor}

\def\sEnsemble#1#2{\mathopen\{#1\mid#2\mathclose\}}
\def\bigEnsemble#1#2{\bigl\{#1\bigm|#2\bigr\}}
\def\BigEnsemble#1#2{\Bigl\{#1\Bigm|#2\Bigr\}}
\def\biggEnsemble#1#2{\biggl\{#1\biggm|#2\biggr\}}
\def\BiggEnsemble#1#2{\Biggl\{#1\Biggm|#2\Biggr\}}
\let\Ensemble=\bigEnsemble

\newcommand\IntO[1]{\left]#1\right[}
\newcommand\IntF[1]{\left[#1\right]}
\newcommand\IntOF[1]{\left]#1\right]}
\newcommand\IntFO[1]{\left[#1\right[}

\newcommand\intO[1]{\mathopen]#1\mathclose[}
\newcommand\intF[1]{\mathopen[#1\mathclose]}
\newcommand\intOF[1]{\mathopen]#1\mathclose]}
\newcommand\intFO[1]{\mathopen[#1\mathclose[}

\newcommand\Fn[3]{#1\colon#2\to#3}
\newcommand\CC[1]{\mathscr{C}^{#1}}
\newcommand\D{\mathop{}\!\mathrm{d}}

\newcommand\longto{\longrightarrow}

\undef\M
\newcommand\M[3]{\mathrm{#1}_{#2}\pa{#3}}
\newcommand\MnR{\M{M}{n}{\R}}
\newcommand\MnC{\M{M}{n}{\C}}
\newcommand\MnK{\M{M}{n}{\K}}
\newcommand\GLnR{\M{GL}{n}{\R}}
\newcommand\GLnC{\M{GL}{n}{\C}}
\newcommand\GLnK{\M{GL}{n}{\K}}
\newcommand\DnR{\M{D}{n}{\R}}
\newcommand\DnC{\M{D}{n}{\C}}
\newcommand\DnK{\M{D}{n}{\K}}
\newcommand\SnR{\M{S}{n}{\R}}
\newcommand\AnR{\M{A}{n}{\R}}
\newcommand\OnR{\M{O}{n}{\R}}
\newcommand\SnRp{\mathrm{S}_n^+(\R)}
\newcommand\SnRpp{\mathrm{S}_n^{++}(\R)}

\newcommand\LE{\mathscr{L}(E)}
\newcommand\GLE{\mathscr{GL}(E)}
\newcommand\SE{\mathscr{S}(E)}
\renewcommand\OE{\mathscr{O}(E)}

\newcommand\ImplD{$\Cro\Rightarrow$}
\newcommand\ImplR{$\Cro\Leftarrow$}
\newcommand\InclD{$\Cro\subset$}
\newcommand\InclR{$\Cro\supset$}
\newcommand\notInclD{$\Cro{\not\subset}$}
\newcommand\notInclR{$\Cro{\not\supset}$}

\newcommand\To[1]{\xrightarrow[#1]{}}
\newcommand\Toninf{\To{\ninf}}

\newcommand\Norm[1]{\|#1\|}
\newcommand\Norme{{\Norm{\cdot}}}

\newcommand\Int[1]{\mathring{#1}}
\newcommand\Adh[1]{\overline{#1}}

\newcommand\Uplet[2]{{#1},\dots,{#2}}
\newcommand\nUplet[3]{(\Uplet{{#1}_{#2}}{{#1}_{#3}})}

\newcommand\Fonction[5]{{#1}\left|\begin{aligned}{#2}&\;\longto\;{#3}\\{#4}&\;\longmapsto\;{#5}\end{aligned}\right.}

\DeclareMathOperator\orth{\bot}
\newcommand\Orth[1]{{#1}^\bot}
\newcommand\PS[2]{\langle#1,#2\rangle}

\newcommand{\Tribu}{\mathscr{T}}
\newcommand{\Part}{\mathcal{P}}
\newcommand{\Pro}{\bigPa{\Omega,\Tribu}}
\newcommand{\Prob}{\bigPa{\Omega,\Tribu,\P}}

\newcommand\DEMO{$\spadesuit$}
\newcommand\DUR{$\spadesuit$}

\newenvironment{psmallmatrix}{\left(\begin{smallmatrix}}{\end{smallmatrix}\right)}


% -----------------------------------------------------------------------------


\newcommand\PSdot{\PS\cdot\cdot}
\newcommand\Pmixte[3]{\cro{#1,#2,#3}}
\newcommand\Signe{\mathop{\mathrm{signe}}}

\begin{document}
\title{Alg\`ebre bilin\'eaire}
\maketitle

% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
\section{Espaces pr\'ehilbertiens r\'eels}

\Para{D\'efinition}
Soit $E$ un $\R$-espace vectoriel de dimension finie ou infinie.
Un \emph{produit scalaire} sur $E$ est une forme bilin\'eaire sym\'etrique d\'efinie positive sur $E$.
Autrement dit, un \emph{produit scalaire} sur $E$ est une application $\Fn{\varphi}{E^2}{\R}$
\begin{enumerate}
\item \emph{bilin\'eaire}:
  $\forall(x,y,z)\in E^3$, $\forall(\lambda,\mu)\in \R^2$,
  \[ \varphi(\lambda x+\mu y,z) = \lambda \varphi(x,z) + \mu \varphi(y,z), \]
  \[ \varphi(x,\lambda y+\mu z) = \lambda \varphi(x,y) + \mu \varphi(x,z). \]
\item \emph{sym\'etrique}: $\forall(x,y)\in E^2$,
  \[ \varphi(y,x) = \varphi(x,y). \]
\item \emph{d\'efinie positive}: $\forall x\in E\setminus\acco{0_E}$,
  \[ \varphi(x,x) > 0. \]
\end{enumerate}

\Para{Proposition}
En pratique, on v\'erifie g\'en\'eralement:
\begin{enumerate}
\item $\varphi\colon E^2 \to\R$ est bien d\'efinie;
\item pour tout $(x,y,z)\in E^3$, pour tout $(\lambda,\mu)\in \R^2$,
  \begin{enumerate}
  \item $\varphi(x,y) = \varphi(y,x)$;
  \item $\varphi(x,\lambda y+\mu z) = \lambda \varphi(x,y) + \mu \varphi(x,z)$;
  \item $\varphi(x,x)\geq0$;
  \item $\varphi(x,x) = 0 \; \Longrightarrow \; x = 0_E$.
  \end{enumerate}
\end{enumerate}

\Para{D\'efinition}
Un \emph{espace pr\'ehilbertien r\'eel} $(E,\varphi)$ est un $\R$-espace vectoriel $E$ muni d'un produit scalaire $\varphi$ sur $E$.
\`A la place de $\varphi(x,y)$, on note g\'en\'eralement $\langle x, y \rangle$, $\langle x \mid y \rangle$, $(x,y)$, $(x\mid y)$ ou encore $x\cdot y$.

\Para{Th\'eor\`eme}[in\'egalit\'e de Cauchy-Schwarz]
Soit $(E,\PSdot)$ un espace pr\'ehilbertien r\'eel.
Alors pour tout $(x,y)\in E^2$,
\[ \BigAbs{ \PS xy } \leq{} \sqrt{\PS xx} \sqrt{\PS yy}. \]
De plus, on a \'egalit\'e si et seulement si $x$ et $y$ sont li\'es.

\Para{Proposition}
Soit $(E,\PSdot)$ un espace pr\'ehilbertien r\'eel.
On d\'efinit $\Fn NE\R$ par $N(x) = \sqrt{\PS xx}$.
Alors $N$ est une norme sur $E$, c.-\`a-d.
\begin{align*}
  \forall{} x \in{} E \setminus{} \Acco{0_E} \+ & \quad N(x) > 0. \\
  \forall{} \lambda{} \in{} \R{} \+ \forall{} x \in{} E \+   & \quad N(\lambda{} x) = \abs{\lambda} N(x). \\
  \forall{} (x,y) \in{} E^2 \+        & \quad N(x+y) \leq{} N(x) + N(y).
\end{align*}

\Para{D\'efinition}
Soit $(E,\PSdot)$ un espace pr\'ehilbertien r\'eel.
On appelle \emph{norme associ\'ee} au produit scalaire $\PSdot$ la norme d\'efinie par
\[ \Norm{x} = \sqrt{\PS xx} \]
Cela fournit une structure d'espace vectoriel norm\'e sur $E$;
on peut donc parler de convergence sur $E$, de topologie sur $E$, etc.

\Para{Proposition}
Soit $(E,\PSdot)$ un espace pr\'ehilbertien r\'eel et $(x,y)\in E^2$.
Alors on a
\begin{enumerate}
\item $\Norm{x+y}^2 = \Norm{x}^2 + \Norm{y}^2 + 2\PS xy$;
\item l'\emph{in\'egalit\'e de Cauchy-Schwarz}:
  $\bigl| \PS xy \bigr| \leq{} \Norm x \cdot{} \Norm y$;
\item l'\emph{identit\'e du parall\'elogramme}:
  $\Norm{x+y}^2 + \Norm{x-y}^2 = 2\bigPa{ \Norm{x}^2 + \Norm{y}^2 }$;
\item l'\emph{identit\'e de polarisation}:
  $\PS xy = \frac14 \bigPa{ \Norm{x+y}^2 - \Norm{x-y}^2 }$.
\end{enumerate}

\Para{Exemples}
\begin{enumerate}
\item Sur $E = \R^n$.
  Si $x = \nUplet x1n\in E$ et $y = \nUplet y1n\in E$,
  on pose \[ \PS xy = \sum_{k=1}^n x_k \, y_k. \]
\item Sur $E = \mathcal{C}([0,1],\R)$.
  Si $(f,g)\in E^2$,
  on pose \[ \PS fg = \int_0^1 f(t) g(t) \D t. \]
\item Et bien d'autres, cf. exercices~1, 2, 3, 4, 6 et~12.
\end{enumerate}

\Para{Notation}
\`A partir de maintenant, $E$ d\'esignera syst\'ematiquement un espace pr\'ehilbertien r\'eel, et son produit scalaire sera not\'e $\PSdot$.

% -----------------------------------------------------------------------------
\subsection{Vecteurs orthogonaux}

\Para{D\'efinition}
Soit $(x,y)\in E^2$.
On dit que les vecteurs $x$ et $y$ sont \emph{orthogonaux} si et seulement si $\PS xy = 0$. On note $x \orth y$.

\Para{D\'efinitions}
Soit $\mathcal{F} = \nUplet x1n$ une famille de vecteurs de $E$.
\begin{itemize}
\item La famille $\mathcal{F}$ est \emph{orthogonale}
  si et seulement si pour tout $(i,j)\in\ccro{1,n}^2$ tels que $i\neq j$,
  on a $\PS{x_i}{x_j} = 0$.
\item La famille $\mathcal{F}$ est \emph{orthonormale} (ou \emph{orthonorm\'ee})
  si et seulement si elle est orthogonale et pour tout $i\in\ccro{1,n}$,
  on a $\Norm{x_i} = 1$.
\item La famille $\mathcal{F}$ est une \emph{base orthonormale}
  (ou \emph{base orthonormale})
  si et seulement si c'est une base et une famille orthonormale.
\end{itemize}

\Para{Proposition}
\begin{enumerate}
\item Une famille orthogonale dont tous les \'el\'ements sont non nuls est libre.
\item Une famille orthonormale est libre.
\item La famille $\nUplet x1n$ est orthonormale si et seulement si
  $\forall(i,j)\in\ccro{1,n}^2$, $\PS{x_i}{x_j} = \delta_{i,j}$.
\item Une base orthonormale est une famille orthonormale qui est \'egalement g\'en\'eratrice.
\end{enumerate}

\Para{Th\'eor\`eme}[Pythagore]
Soit $\nUplet x1n$ une famille orthogonale de vecteurs de $E$.
Alors \[ \left\| \sum_{i=1}^n x_i \right\|^2 = \sum_{i=1}^n \Norm{x_i}^2. \]

\Para{Th\'eor\`eme}[r\'eciproque de Pythagore]
Soit $(x,y)\in E^2$.
Si $\Norm{x+y}^2 = \Norm{x}^2 + \Norm{y}^2$,
alors $x$ et $y$ sont orthogonaux.

\Para{Th\'eor\`eme}[proc\'ed\'e de Gram-Schmidt]
Soit $\nUplet x1p$ une famille \emph{libre} de vecteurs de $E$.
Alors il existe une \emph{unique} famille $\nUplet e1p$ de vecteurs de $E$
telle que
\begin{itemize}
\item la famille $\nUplet e1p$ est orthonorm\'ee,
\item pour tout $n\in\ccro{1,p}$, \[ \Vect \nUplet x1n = \Vect \nUplet e1n, \]
\item pour tout $n\in\ccro{1,p}$, $\PS{x_n}{e_n} > 0$.
\end{itemize}
De plus, on peut la calculer avec les formules suivantes:
\begin{itemize}
\item $\widetilde{e_1} = x_1$;
\item pour $n\in\ccro{2,p}$, on note
  \[ \widetilde{e_n} = x_n - \sum_{k=1}^{n-1} \PS{e_k}{x_n} e_k
  = x_n -\sum_{k=1}^{n-1} \frac{\PS{\widetilde{e_k}}{x_n}}{\Norm{\widetilde{e_k}}^2} \widetilde{e_k}; \]
\item pour $n\in\ccro{1,p}$, on a
  $\DS e_n = \frac1{\Norm{\widetilde{e_n}}} \, \widetilde{e_n}$.
\end{itemize}

\Para{Corollaire}[proc\'ed\'e de Gram-Schmidt infini]
Soit $(x_n)_{n\in \N}$ une famille libre de vecteurs de $E$.
Alors il existe une unique famille $(e_n)_{n\in \N}$
telle que
\begin{itemize}
\item la famille $(e_n)_{n\in \N}$ est orthonorm\'ee,
\item pour tout $n\in \N$, \[ \Vect \nUplet x0n = \Vect \nUplet e0n, \]
\item pour tout $n\in \N$, $\PS{x_n}{e_n} > 0$.
\end{itemize}
De plus, on peut la calculer avec les formules suivantes:
\begin{itemize}
\item $\widetilde{e_0} = x_0$;
\item pour $n\in\Ns$, on note
  \[ \widetilde{e_n} = x_n - \sum_{k=0}^{n-1} \PS{e_k}{x_n} e_k
  = x_n -\sum_{k=0}^{n-1} \frac{\PS{\widetilde{e_k}}{x_n}}{\Norm{\widetilde{e_k}}^2} \widetilde{e_k}; \]
\item pour $n\in \N$, on a
  $\DS e_n = \frac1{\Norm{\widetilde{e_n}}} \, \widetilde{e_n}$.
\end{itemize}

\Para{Proposition}[Bessel-Parseval en dimension finie]
Si $\nUplet e1n$ une base orthonormale de $E$,
alors pour tout $x\in E$, on a
\[ x = \sum_{k=1}^n \PS{e_k}{x} e_k \quad\text{et}\quad \Norm{x}^2 = \sum_{k=1}^n \PS{e_k}{x}^2. \]

\Para{Th\'eor\`eme}[in\'egalit\'e de Bessel]
Soit $\mathcal{F} = (e_n)_{n\in \N}$ une famille orthonorm\'ee et $x\in E$.
Alors la s\'erie de terme g\'en\'eral $\PS{e_n}{x}^2$ converge et
\[ \sum_{n=0}^{+\infty} \PS{e_n}{x}^2 \leq{} \Norm{x}^2. \]
De plus, si l'on suppose que $\Vect(\mathcal{F})$ est dense dans $E$,
on a alors l'\'egalit\'e (dite de Parseval).

% -----------------------------------------------------------------------------
\subsection{Sous-espaces orthogonaux}

\Para{D\'efinitions}
Soit $F$ et $G$ deux sous-espaces vectoriels et $x\in E$.
\begin{itemize}
\item \emph{$x$ est orthogonal \`a $F$}
  si et seulement si $x$ est orthogonal \`a tout vecteur de $F$.
  On note alors $x \orth F$.
\item \emph{$F$ est orthogonal \`a $G$}
  si et seulement si pour tout $(x,y)\in F\times G$, on a $x \orth y$.
  On note alors $F \orth G$.
\end{itemize}

\Para{D\'efinition}
Soit $A\subset E$.
On d\'efinit \emph{l'orthogonal de $A$}, not\'e $\Orth A$,
comme \'etant $\Ensemble{x\in E}{x \orth A}$.
Autrement dit,
\[ \forall x\in E\+ \Big( x\in\Orth A \iff \forall a\in A\+ \PS ax = 0 \Big). \]

\Para{Proposition}
Soit $A\subset E$.
Alors:
\begin{itemize}
\item $\Orth A$ est un sous-espace vectoriel de $E$;
\item $\Orth A = \Orth{\Vect(A)}$;
\item $x \orth A$ si et seulement si $x\in\Orth A$.
\end{itemize}

\Para{Proposition}
Soit $\Uplet{F_1}{F_n}$ des sous-espaces vectoriels de $E$ deux \`a deux orthogonaux.
Alors ils sont en somme directe.

\Para{D\'efinition}
Soit $\Uplet{F_1}{F_n}$ des sous-espaces vectoriels de $E$ deux \`a deux orthogonaux.
On dit qu'ils sont en \emph{somme directe orthogonale} et l'on note leur somme
\[ \sum_{k=1}^n F_k = \bigoplus_{k=1}^{\substack{n\\\bot}} F_k. \]
De plus, si cette somme vaut $E$, on dit qu'ils sont \emph{suppl\'ementaires orthogonaux}.

\Para{Th\'eor\`eme}
Soit $F$ un sous-espace vectoriel \emph{de dimension finie} de $E$.
Alors $E = F \oplus{} F^{\bot}$ et $F^{\bot\bot} = F$.

\Para{Remarques}
\begin{enumerate}
\item On ne fait pas d'hypoth\`ese sur la dimension de $E$.
\item Si l'on ne suppose plus que $F$ est de dimension finie, on a seulement $F\oplus\Orth F\subset E$ et $F^{\bot\bot}\supset F$,
  et ces deux inclusions peuvent \^etre strictes.
\end{enumerate}

% -----------------------------------------------------------------------------
\subsection{Projection orthogonale}

\Para{Notation}
Dans ce paragraphe, $F$ d\'esignera toujours
un sous-espace vectoriel de $E$ tel que $E = F \oplus{} \Orth F$;
c'est toujours le cas si $F$ est de dimension finie.

\Para{D\'efinition}
On appelle \emph{projection orthogonale} sur $F$ la projection, not\'ee $p_F$, sur $F$ parall\`element \`a $\Orth F$.

Autrement dit, si
\[ x = \underbrace{y}_{\vphantom{\Orth F}\in F} + \underbrace{\vphantom{y}z}_{\in\Orth F}, \]
alors $p_F(x) = y$.

\Para{Th\'eor\`eme}
Soit $(x,y)\in E^2$. Les conditions suivantes sont \'equivalentes:
\begin{enumerate}
\item $y = p_F(x)$.
\item $y\in F$ et $x - y\in\Orth F$.
\item $y\in F$ et $\forall z\in F\+ \Norm{x - z}\geq\Norm{x - y}$.
\end{enumerate}

\Para{Corollaires}
Soit $x\in E$.
\begin{enumerate}
\item Pour tout $y\in F$, on a $\Norm{x-y}\geq\Norm{x-p_F(x)}$
  avec \'egalit\'e si et seulement si $y = p_F(x)$.
\item La fonction $\Fonction{f}{F}{\R}{y}{d(x,y) = \Norm{x-y}}$
  atteint son minimum en un unique point $y = p_F(x)$.
\item $\inf_{y\in F} \Norm{x - y} = \Norm{x - p_F(x)}$.
\item $d(x,F) = d(x,p_F(x)) = \Norm{x - p_F(x)}$.
\end{enumerate}

\Para{Proposition}
On suppose que $F$ est de dimension finie.
Soit $\nUplet e1n$ une base orthonormale de $F$.
Alors, pour tout $x\in E$, la projection orthogonale de $x$ sur $F$ est donn\'ee par la formule
\[ p_F(x) = \sum_{k=1}^n \PS{e_k}{x} e_k. \]

\Para{Remarque}[calcul pratique]
On suppose que $F$ est de dimension finie.
Soit $\B = \nUplet u1n$ une base de $F$ et $x\in E$.
Pour calculer $p_F(x)$, on a en g\'en\'eral deux m\'ethodes:
\begin{enumerate}
\item On orthonormalise $\B$
  puis on applique ensuite la formule de la proposition pr\'ec\'edente.
  Le probl\`eme est que les calculs de l'orthonormalisation sont souvent peu agr\'eables.
\item On note $p_F(x) =\sum_{j=1}^n\alpha_j u_j$
  et on \'ecrit
  $\forall i\in\Dcro{1,n}$, $\PS{u_i}{p_F(x)-x} = 0$.
  Cela fournit un syst\`eme de $n$ \'equations lin\'eaires \`a $n$ inconnues:
  \[ \rule{-1\labelwidth}{0pt}
    \left\{ \begin{array}{c@{}c@{}c@{}c@{}c@{}c@{}c@{}c@{}c}
        \alpha_1 \PS{u_1}{u_1} & {}+{} & \alpha_2 \PS{u_1}{u_2} & {}+{} & \cdots & {}+{} & \alpha_n \PS{u_1}{u_n} & {}={} & \PS{u_1}{x} \\
        \alpha_1 \PS{u_2}{u_1} & {}+{} & \alpha_2 \PS{u_2}{u_2} & {}+{} & \cdots & {}+{} & \alpha_n \PS{u_2}{u_n} & {}={} & \PS{u_2}{x} \\
        \cdots            &       & \cdots            &       & \cdots &       & \cdots            &       & \cdots      \\
        \alpha_1 \PS{u_n}{u_1} & {}+{} & \alpha_2 \PS{u_n}{u_2} & {}+{} & \cdots & {}+{} & \alpha_n \PS{u_n}{u_n} & {}={} & \PS{u_n}{x}
  \end{array} \right. \]
  Ce syst\`eme est n\'ecessairement de Cramer.
  Il ne reste plus qu'\`a le r\'esoudre, ce qui nous donne $\nUplet\alpha1n$ et donc $p_F(x)$.
\end{enumerate}

\Para{D\'efinition}
On appelle \emph{sym\'etrie orthogonale} par rapport \`a $F$
la sym\'etrie, not\'ee $s_F$, par rapport \`a $F$ et parall\`element \`a $\Orth F$.
Autrement dit, si
$x = y + z$ o\`u $y\in F$ et $z\in\Orth F$,
alors $s_F(x) = y - z$.

\Para{Proposition}
Avec les m\^emes notations, $s_F = 2p_F - \Id_E$.

\Para{D\'efinition}
Une \emph{r\'eflexion} est une sym\'etrie orthogonale par rapport \`a un hyperplan.

% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
\section{Espaces euclidiens}

\Para{D\'efinition}
Un \emph{espace euclidien} est un espace pr\'ehilbertien r\'eel de dimension finie.

\Para{Notation}
\`A partir de maintenant, $E$ d\'esignera toujours un espace euclidien de dimension $n\geq1$.

\Para{Th\'eor\`eme}[base orthonormale incompl\`ete]
On peut compl\'eter toute famille orthonormale de vecteurs de $E$ en une base orthonormale de $E$.

\Para{Th\'eor\`eme}[Riesz]
Soit $\Fn fE\R$ une forme lin\'eaire sur $E$.
Alors il existe un unique $a\in E$ tel que pour tout $x\in E$, $f(x) = \PS ax$.

\Para{Corollaire}
Tout hyperplan de $E$ est de la forme $\Orth{\Acco x}$
pour un $x\in E\setminus\acco{0_E}$.

\Para{Lemme}
On note $(\,\cdot\, | \,\cdot\,)$ le produit scalaire usuel sur $\R^n$.
Soit $\B$ une base orthonormale de $E$.
Soit $x$ et $y$ deux vecteurs de $E$.
On pose $X = \Coords_\B(x)$ et $Y = \Coords_\B(y)$.
Alors $\PS{x}{y} = (X\mid Y) = \T X Y$.

% -----------------------------------------------------------------------------
\subsection{Endomorphismes sym\'etriques}

\Para{D\'efinition}
Soit $u\in\LE$.
On dit que $u$ est un endomorphisme \emph{sym\'etrique} (ou \emph{autoadjoint}) si et seulement si $\forall(x,y)\in E^2$, $\PS{u(x)}{y} = \PS{x}{u(y)}$.
On note $\SE$ l'ensemble des endomorphismes sym\'etriques de $E$.
Il s'agit d'un sous-espace vectoriel de $\LE$.

\Para{Proposition}
Soit $u\in\LE$.
Les conditions suivantes sont \'equivalentes:
\begin{enumerate}[label=\roman*.]
\item $u$ est un endomorphisme sym\'etrique;
\item pour toute base orthonormale $\B$ de $E$,
  $\Mat_\B(u)$ est une matrice sym\'etrique;
\item il existe une base orthonormale $\B$ de $E$
  telle que $\Mat_\B(u)$ est une matrice sym\'etrique.
\end{enumerate}

% -----------------------------------------------------------------------------
\subsection{Endomorphismes orthogonaux}

\Para{Proposition}
Soit $M\in\MnR$. Les conditions suivantes sont \'equivalentes:
\begin{enumerate}[label=\roman*.]
\item $\T M M = I_n$;
\item $M \T M = I_n$;
\item $M$ est inversible et $M^{-1} = \T M$;
\item les colonnes de $M$
  forment une base orthonormale de $\R^n$ muni du produit scalaire usuel;
\item les lignes de $M$
  forment une base orthonormale de $\R^n$ muni du produit scalaire usuel.
\end{enumerate}

\Para{D\'efinition}
On dit que la matrice $M$ est \emph{orthogonale} lorsque ces conditions sont v\'erifi\'ees.
On note $\OnR$ l'ensemble des matrices orthogonales de $\MnR$.

\Para{Proposition}
$\OnR$ est un sous-groupe de $(\GLnR,\times)$; c'est pourquoi $\OnR$ est appel\'e le \emph{groupe orthogonal}.
Autrement dit:
\begin{enumerate}
\item Si $A\in\OnR$, alors $A$ est une matrice inversible et $A^{-1}\in\OnR$.
\item Si $(A,B)\in\OnR$, alors $AB\in\OnR$.
\end{enumerate}

\Para{Proposition}
La matrice de passage entre deux bases orthonorm\'ees de $E$ est une matrice orthogonale.

Plus g\'en\'eralement, si $\B$ est une base orthonormale,
$\Pass(\B\to\B')$ est une matrice orthogonale si et seulement si $\B'$ est une base orthonormale.

\Para{D\'efinition}
Soit $u\in\LE$.
On dit que $u$ est un endomorphisme \emph{orthogonal} si et seulement si
$\forall(x,y)\in E^2$, $\PS{u(x)}{u(y)} = \PS xy$.
On note $\OE$ l'ensemble des endomorphismes orthogonaux de $E$.
Il s'agit d'un sous-groupe de $\GLE$.

\Para{D\'efinition}
Soit $u\in\LE$.
On dit que $u$ est une \emph{isom\'etrie}
si et seulement si $\forall x\in E$, $\Norm{u(x)} = \Norm{x}$.

\Para{Proposition}
Soit $u\in\LE$. Les conditions suivantes sont \'equivalentes:
\begin{enumerate}[label=\roman*.]
\item $u$ est une isom\'etrie;
\item $u$ est un endomorphisme orthogonal;
\item pour toute base orthonormale $\B$ de $E$,
  $\Mat_\B(u)$ est une matrice orthogonale;
\item il existe une base orthonormale $\B$ de $E$ telle que
  $\Mat_\B(u)$ est une matrice orthogonale.
\end{enumerate}

% -----------------------------------------------------------------------------
\subsection{Th\'eor\`eme spectral}

\Para{Lemmes techniques}
\begin{enumerate}
\item Soit $u\in\SE$.
  Alors les sous-espaces propres de $u$ sont deux \`a deux orthogonaux.
\item Soit $u\in\SE$ et $F$ un sous-espace vectoriel stable par $u$.
  Alors $\Orth F$ est stable par $u$.
\item Soit $A\in\SnR$.
  Alors $\Sp_\C(A)\subset \R$.
\item Soit $u\in\SE$.
  Alors $\Sp u\neq\emptyset$.
\end{enumerate}

\Para{Th\'eor\`eme}[th\'eor\`eme spectral]
Soit $u$ un endomorphisme sym\'etrique de $E$.
Alors $u$ est \emph{diagonalisable en base orthonormale}, c.-\`a-d. qu'il existe
une base orthonormale $\B$ telle que $\Mat_\B(u)$ soit diagonale.
De plus, les sous-espaces propres de $u$ sont suppl\'ementaires orthogonaux, c.-\`a-d.
\[ E = \mathop{\bigoplus}^\bot_{\lambda\in\Sp u} E_\lambda{} \]
o\`u $E_\lambda{} = \Ker(u-\lambda\Id_E)$.

\Para{Th\'eor\`eme}[th\'eor\`eme spectral, version matricielle]
Soit $A\in\SnR$.
Alors il existe $P\in\OnR$ et $D\in\DnR$
tels que $A = P D P^{-1} = P D \T P$.

% -----------------------------------------------------------------------------
% -----------------------------------------------------------------------------
\section{Un peu de g\'eom\'etrie}

\Para{Proposition-D\'efinition}
Soit $(x,y)\in E^2$ deux vecteurs non nuls.
Alors il existe un unique $\theta\in[0,\pi]$ tel que
\[ \PS{x}{y} = \Norm{x} \Norm{y} \cos\theta, \]
et ce $\theta$ s'appelle l'\emph{angle g\'eom\'etrique} entre les vecteurs $x$ et $y$.

\Para{Proposition}
Soit $f\in \OE$. Alors
\begin{itemize}
\item $\det f =\pm1$,
\item $\Sp_\R f\subset\Acco{-1,1}.$
\end{itemize}

\Para{D\'efinitions}
Soit $f\in \OE$.
\begin{itemize}
\item Si $\det f = 1$,
  on dit que $f$ est une \emph{isom\'etrie directe}.
  L'ensemble des isom\'etries directes de $E$ se note $\mathcal{O}^+(E)$ ou
  $\mathcal{SO}(E)$; il s'agit d'un sous-groupe de $\OE$.
\item Si $\det f = -1$,
  on dit que $u$ est une \emph{isom\'etrie indirecte}.
  L'ensemble des isom\'etries directes de $E$ se note $\mathcal{O}^-(E)$.
\end{itemize}

\Para{Proposition}
Soit $A\in\OnR$. On a n\'ecessairement $\det A =\pm1$.

\Para{D\'efinitions}
L'ensemble des matrices de $\OnR$ de d\'eterminant~$1$
se note $\mathrm{O}_n^+(\R)$ ou $\mathrm{SO}_n(\R)$;
il s'agit d'un sous-groupe de $\OnR$ appel\'e
\emph{groupe sp\'ecial orthogonal}.
L'ensemble des matrices de $\OnR$ de d\'eterminant~$-1$
se note $\mathrm{O}_n^-(\R)$.

% -----------------------------------------------------------------------------
\subsection{D\'eterminant, rappels et compl\'ements}

\Para{D\'efinition}
Soit $n$ la dimension de $E$, $\B$ une base de $E$ et $\nUplet x1n$ des vecteurs de $E$.
On note $\det_\B\nUplet x1n$ le d\'eterminant de la matrice dont la $j$-\`eme colonne vaut
$\Coords_\B(x_j)$.

\Para{Proposition}
Soit $u\in\LE$ et $\B$ une base de $E$.
Soit $\nUplet x1n\in E^n$ o\`u $n = \dim E$.
Alors \[ \det_\B \bigPa{\Uplet{u(x_1)}{u(x_n)}} = \det(u) \det_\B \nUplet x1n. \]

\Para{Proposition}
Soit $\B$, $\B'$ deux bases de $E$ et $P$ la matrice de passage de $\B$ \`a $\B'$.
Soit $\nUplet x1n\in E^n$ o\`u $n = \dim E$.
Alors \[ \det_\B \nUplet x1n = \det(P) \det_{\B'} \nUplet x1n. \]

\Para{D\'efinition}
Soit $\B$ et $\B'$ deux bases de $E$.
On dit que $\B$ et $\B'$ ont \emph{m\^eme orientation} si et seulement si $\det\bigPa{\Pass(\B,\B')} > 0$.

\Para{Proposition}
Il s'agit d'une relation d'\'equivalence, c.-\`a-d.:
\begin{enumerate}
\item \emph{r\'eflexivit\'e}: toute base a la m\^eme orientation qu'elle-m\^eme;
\item \emph{sym\'etrie}: si $\B$ et $\B'$ ont la m\^eme orientation, alors $\B'$ et $\B$ ont la m\^eme orientation;
\item \emph{transitivit\'e}: deux bases ayant la m\^eme orientation qu'une m\^eme troisi\`eme ont la m\^eme orientation.
\end{enumerate}
Pour cette relation, il y a deux classes d'\'equivalences.

\Para{D\'efinition}
Orienter un espace vectoriel, c'est convenir d'appeler \emph{directes} les bases de l'une des deux classes, et \emph{indirectes} les bases de l'autre.

% -----------------------------------------------------------------------------
\subsection{Classification des isom\'etries du plan}

\Para{Contexte}
On se place dans le cadre d'un espace euclidien orient\'e $E$ de dimension $2$.

\Para{Lemme}
Soit $M\in\mathrm{O}_2^+(\R)$.
Alors il existe $\theta\in \R$, unique modulo $2\pi$, tel que
\[ M = R_\theta{} = \begin{pmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{pmatrix}. \]
De plus, $R_\theta R_{\theta'} = R_{\theta+\theta'}$.

\Para{Th\'eor\`eme}
Soit $f\in\mathcal{O}^+(E)$.
Alors il existe un $\theta\in \R$, unique modulo $2\pi$, tel que
pour toute base orthonormale directe $\B$ de $E$, on ait $\Mat_\B(f) = R_\theta$.
On dit que $f$ est la \emph{rotation d'angle $\theta$}.
De plus, si $x\in E$ v\'erifie $\Norm x = 1$,
alors $\cos\theta= \PS{x}{f(x)}$ et $\sin\theta= \det(x,f(x))$.

\Para{Th\'eor\`eme}
Soit $f\in\mathcal{O}^-(E)$.
Alors pour toute base orthonormale directe $\B$ de $E$,
il existe $\theta\in \R$, unique modulo $2\pi$, tel que
\[ \Mat_\B(f) = \begin{pmatrix} \cos\theta & \sin\theta \\ \sin\theta & -\cos\theta \end{pmatrix}. \]
De plus, $f$ est la r\'eflexion d'axe le vecteur de coordonn\'ees $\begin{pmatrix} \cos(\theta/2) \\ \sin(\theta/2) \end{pmatrix}$.

% -----------------------------------------------------------------------------
\subsection{Produit mixte, produit vectoriel}

\Para{Contexte}
On se place dans le cadre d'un espace euclidien orient\'e $E$
de dimension $3$.

\Para{Proposition}
Soit $\B_1$ et $\B_2$ deux bases orthonorm\'ees directes de $E$.
Alors $\det_{\B_1} = \det_{\B_2}$,
c.-\`a-d.
\[ \forall(x,y,z)\in E^3\+ \det_{\B_1}(x,y,z) = \det_{\B_2}(x,y,z). \]

\Para{D\'efinition}
Soit $(x,y,z)\in E^3$.
On d\'efinit le \emph{produit mixte} des trois vecteurs $x$, $y$ et $z$ par
\[ \Pmixte xyz = \det_\B(x,y,z) \]
pour une base orthonorm\'ee directe $\B$ quelconque.

\Para{Proposition-D\'efinition}
Soit $(u,v)\in E^2$.
Alors il existe un unique vecteur $w\in E$ tel que
\[ \forall x\in E, \quad \Pmixte uvx = \PS{w}{x}. \]
Le vecteur $w$, que l'on note $u \wedge v$, s'appelle le \emph{produit vectoriel} de $u$ et $v$.

\Para{Remarque}
Le produit vectoriel est donc enti\`erement caract\'eris\'e par la formule
\[ \forall(x,y,z)\in E^3\+ \Pmixte xyz = \PS{x \wedge y}{z}. \]

\Para{Proposition}
Si $(u,v,w)\in E^2$ et $(\lambda,\mu)\in \R^2$, on a:
\begin{itemize}
\item $(\lambda u+\mu v) \wedge w = \lambda(u \wedge w) + \mu(v \wedge w)$;
\item $u \wedge (\lambda v+\mu w) = \lambda(u \wedge v) + \mu(u \wedge w)$;
\item $u \wedge u = 0$;
\item $u \wedge v = - (v \wedge u)$;
\item $u \wedge v\in\Orth{\Vect(u,v)}$;
\item $u \wedge v = 0$ si et seulement si $u$ et $v$ sont li\'es;
\item si $(u,v)$ est libre,
  alors $(u,v,u \wedge v)$ est une base directe de $E$;
\item si $(u,v)$ est orthonorm\'ee,
  alors $(u,v,u \wedge v)$ est une base orthonorm\'ee directe de $E$;
\item $u \wedge (v \wedge w) = \PS{u}{w}{v} - \PS{u}{v}{w}$.
  Il s'agit de la \emph{formule du double produit vectoriel};
\item si $\theta$ est l'angle $(u,v)$,
  alors
  $\PS uv = \Norm u \Norm v \cos\theta$
  et
  $\Norm{u \wedge v} = \Norm u \Norm v \, \Abs{\sin\theta}$.
\end{itemize}

% -----------------------------------------------------------------------------
\subsection{Classification des isom\'etries de l'espace}

\Para{Contexte}
On se place dans le cadre d'un espace euclidien orient\'e $E$ de dimension $3$.

\Para{Proposition-D\'efinition}
Soit $f\in\mathcal{O}^+(E)$.
Alors il existe une base orthonorm\'ee directe $\B = (u_1,u_2,u_3)$
telle que
\[ \Mat_\B(f) = \begin{pmatrix} 1 & 0 & 0 \\ 0 & \cos\theta & -\sin\theta \\ 0 & \sin\theta & \cos\theta \end{pmatrix} = \begin{pmatrix} 1 & \\ & R_\theta \end{pmatrix}. \]
On dit que $f$ est la rotation d'axe $u_1$ et d'angle $\theta$.
De plus,
\begin{itemize}
\item $\Tr f = 1+2\cos\theta$,
  ce qui permet de d\'eterminer $\theta$ au signe pr\`es;
\item si la famille $(u_1,v)$ est libre,
  alors $\Signe(\sin\theta) = \Signe \Pmixte{u_1}{v}{f(v)}$.
\end{itemize}

\Para{Proposition}
Soit $f\in\mathcal{O}^-(E)$.
Alors il existe une base orthonorm\'ee directe $\B = (u_1,u_2,u_3)$
telle que
\[ \Mat_\B(f) = \begin{pmatrix} -1 & 0 & 0 \\ 0 & \cos\theta & -\sin\theta \\ 0 & \sin\theta & \cos\theta \end{pmatrix} = \begin{pmatrix} -1 & \\ & R_\theta \end{pmatrix}. \]
$f$ est la compos\'ee commutative de la rotation d'axe $u_1$ et d'angle $\theta$
et de la r\'eflexion par rapport au plan $\Orth{\Vect(u_1)}$.
De plus,
\begin{itemize}
\item $\Tr f = -1+2\cos\theta$,
  ce qui permet de d\'eterminer $\theta$ au signe pr\`es;
\item si la famille $(u_1,v)$ est libre,
  alors $\Signe(\sin\theta) = \Signe \Pmixte{u_1}{v}{f(v)}$.
\end{itemize}

% -----------------------------------------------------------------------------
\section{Exercices}

\subsection{Espaces pr\'ehilbertiens}

\subsubsection{Produits scalaires}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 1}%
\hfill{\tiny 5192}%
\begingroup~

V\'erifier que $\PS\cdot\cdot$ est un produit scalaire sur $E$ dans les cas suivants.
\begin{enumerate}
\item $E = \MnR$
  et $\PS AB = \Tr\bigPa{\T{A}B}$.
\item $E = \mathcal{C}([-1,1],\R)$
  et $\DS \PS fg = \int_{-1}^1 \frac{f(t)g(t)}{\sqrt{1-t^2}}\D t$.
\item $E = \BigEnsemble{\Fn{f}{\R}{\R}\text{ continues}}{ f^2 \text{ int\'egrable sur }\R}$
  et $\DS \PS fg = \int_\R{} fg$.
\item $E = \R[X]$
  et $\DS \PS PQ =\int_0^1 P(t)Q(t)\D t$.
\item $E = \R[X]$
  et $\DS \PS PQ =\sum_{n=0}^{+\infty} \frac{P(n)Q(n)}{2^n}$.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 2}%
\hfill{\tiny 0385}%
\begingroup~

Soit $n\in \N$ fix\'e, $E = \R_n[X]$ et $F = \Ensemble{P\in E}{P(0)=P(1)=0}$.
Pour $(P,Q)\in E$, on pose \[ \varphi(P,Q) = -\int_0^1 (PQ''+P''Q). \]
\begin{enumerate}
\item V\'erifier que $F$ est un espace vectoriel.
\item Donner une base et la dimension de $F$.
\item $\varphi$ d\'efinit-il un produit scalaire sur $E$? sur $F$?
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 3}%
\hfill{\tiny 0694}%
\begingroup~

Soit $E$ euclidien et $\B = \nUplet e1n$ une bon de $E$.
On pose \[ \Fonction{\varphi}{\LE\times\LE}{\R}{(u,v)}{\sum_{i=1}^n \PS{u(e_i)}{v(e_i)}} \]
Montrer que $\varphi$ est un produit scalaire sur $\LE$,
et d\'eterminer une base orthonormale pour ce produit scalaire.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 4}%
\hfill{\tiny 9245}%
\begingroup~

Soit $E$ l'ensemble des suites r\'eelles $(u_n)_{n\in \N}$ telles que la s\'erie de terme g\'en\'eral $u_n^2$ converge.
Pour $u$ et $v$ dans $E$, on pose
\[ \PS uv = \sum_{n=0}^{+\infty} u_n v_n. \]
\begin{enumerate}
\item Montrer que $E$ est un espace vectoriel. On le note usuellement $\ell^2$.
\item Montrer que $\PS uv$ existe.
\item Montrer qu'il s'agit d'un produit scalaire.
\end{enumerate}
\endgroup

\subsubsection{Polyn\^omes orthogonaux}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 5}%
\hfill{\tiny 3281}%
\begingroup~

On munit le $\R$-espace vectoriel $E = \mathcal{C}([-1,1],\R)$
du produit scalaire usuel d\'efini par
\[ \forall(f,g)\in E^2 \+ \PS fg = \int_{-1}^1 f(t) g(t) \D t. \]
On pose pour tout $n\in \N$,
\[ L_n(X) = \frac{1}{2^n n!}\cdot\frac{\mathrm{d}^n}{\mathrm{d}X^n} \Big[ (X^2-1)^n \Big] \]
Les polyn\^omes $\bigl(L_n(X)\bigr)_{n\in \N}$ s'appellent \emph{polyn\^omes de Legendre}.
On pourra introduire $H_n(X) = (X^2-1)^n$.\begin{enumerate}
\item Montrer que $L_n$ est un polyn\^ome de degr\'e $n$
  dont on pr\'ecisera le coefficient dominant.
\item En utilisant la formule de Leibniz, calculer $L_n(1)$ et $L_n(-1)$.
\item Avec une int\'egration par parties multiple, calculer $\PS{L_n}{L_n}$.
\item Calculer $\PS{Q}{L_n}$ lorsque $Q$ est un polyn\^ome de $\R_{n-1}[X]$.
\item En d\'eduire $\PS{L_n}{L_m}$ lorsque $n\neq m$.
\item Comparer $(L_n)_{n\in \N}$ \`a l'orthonormalis\'ee de la base canonique.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/6416.pdf}{Exercice 6}}%
\hfill{\tiny 6416}%
\begingroup~

\newcommand\HR[1]{\mathcal{H}_{#1}}
Soit $E = \R[X]$.
On pose, pour $(P,Q)\in E^2$,
\[ \PS PQ = \frac2\pi\int_{-1}^1 \sqrt{1-t^2} \, P(t) Q(t) \D t \]
\begin{enumerate}
\item
  Montrer que $\PS\cdot\cdot$ est bien un produit scalaire sur $E$.
\item
  Soit $n\in \N$.
  Montrer qu'il existe un unique polyn\^ome $U_n$ tel que
  \[ \forall \theta\in \R{} \+ \sin\bigPa{(n+1)\theta} = \sin(\theta) U_n(\cos\theta). \]

  Les polyn\^omes $\bigPa{U_n(X)}_{n\in \N}$ s'appellent
  les \emph{polyn\^omes de Tchebychev de seconde esp\`ece}.
\item
  Comparer $(U_n)_{n\in \N}$ \`a l'orthonormalis\'ee de la base canonique.
\end{enumerate}
\endgroup

\subsubsection{Projection orthogonale}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 7}%
\hfill{\tiny 2240}%
\begingroup~

Soit $E$ un espace euclidien et $\B = (e_1,e_2,e_3,e_4)$ une base orthonormale de $E$.
On consid\`ere le sous-espace vectoriel $F$ d'\'equations dans $\B$:
\[ \left\{ \begin{alignedat}{5}
      x_1 & {}+{} & x_2  & {}+{} & x_3  & {}+{} & x_4  & {}={} & 0 \\
      x_1 & {}+{} & 2x_2 & {}+{} & 3x_3 & {}+{} & 4x_4 & {}={} & 0
\end{alignedat} \right. \]
\begin{enumerate}
\item Quelle est la dimension de $F$?
\item D\'eterminer $\Orth F$.
\item Trouver une base orthonormale de $F$.
\item Donner la matrice de la projection orthogonale sur $F$.
\item Calculer la distance de $e_1=(1,0,0,0)$ \`a $F$.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 8}%
\hfill{\tiny 0552}%
\begingroup~

Soit $\mathcal{E} = \MnR$ muni du produit scalaire usuel
$\PS AB = \Tr\bigl(\T A B\bigr)$.\begin{enumerate}
\item Montrer que $\mathcal{S}$ et $\mathcal{A}$ sont suppl\'ementaires orthogonaux,
  o\`u $\mathcal{S}$ d\'esigne l'ensemble des matrices sym\'etriques
  et $\mathcal{A}$ l'ensemble des matrices antisym\'etriques.
\item Montrer que
  \[ \forall A\in\mathcal{E} \+ \Tr A \leq{} \sqrt{n\Tr(\T A A)}. \]
  \'Etudier le cas d'\'egalit\'e.
\item Pour $A\in\mathcal{E}$, on pose
  \[ \Fonction{f_A}{\mathcal{S}}{\R}{S}{\sum_{i=1}^n\sum_{j=1}^n (a_{i,j} - s_{i,j})^2} \]
  D\'eterminer le minimum de $f_A$ et la matrice qui r\'ealise ce minimum.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 9}%
\hfill{\tiny 7473}%
\begingroup~

D\'eterminer $(a,b,c,d)\in \R^4$ tels que l'int\'egrale
\[ \int_{-\pi/2}^{\pi/2} \Big( \sin x - ax^3 - bx^2 - cx - d \Big)^2 \D x \]
soit minimale.

% -----------------------------------------------------------------------------
\endgroup

\subsection{Espaces euclidiens}

\subsubsection{Endomorphismes sym\'etriques}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 10}%
\hfill{\tiny 7759}%
\begingroup~

Soit $A$ une matrice sym\'etrique r\'eelle telle que $A^2 = 0$.
Montrer que $A = 0$.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 11}%
\hfill{\tiny 6393}%
\begingroup~

Soit $A = (a_{ij})$ une matrice r\'eelle sym\'etrique.
On note $\Uplet{\lambda_1}{\lambda_n}$ ses valeurs propres.
Montrer que
\[ \sum_{k=1}^n\lambda_k^2 = \sum_{i=1}^n \sum_{j=1}^n a_{ij}^2. \]
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 12}%
\hfill{\tiny 7523}%
\begingroup~

Soit $E = \R_n[X]$. Pour $(P,Q)\in E^2$, on pose
\[ \PS PQ = \int_{-1}^1 \frac{P(t)Q(t)}{\sqrt{1-t^2}} \D t. \]
\begin{enumerate}
\item Montrer qu'il s'agit bien d'un produit scalaire.
\item Montrer que $u \colon P \mapsto (X^2-1)P''+XP'$ est un endomorphisme sym\'etrique
  pour ce produit scalaire.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 13}%
\hfill{\tiny 3294}%
\begingroup~

Soit $A\in\SnR$ et $p\in \N^*$ telle que $A^p = I_n$.
Montrer que $A^2 = I_n$.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/3962.pdf}{Exercice 14}}%
\hfill{\tiny 3962}%
\begingroup~

Soit $u\in\mathcal{S}(E)$. Montrer que $\Ker u$ et $\Ima u$ sont des
suppl\'ementaires orthogonaux.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/3217.pdf}{Exercice 15}}%
\hfill{\tiny 3217}%
\begingroup~

Soit $u,v\in\mathcal{S}(E)$.
Montrer que $u\circ v$ est sym\'etrique si et seulement si $u$ et $v$ commutent.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 16}%
\hfill{\tiny 1117}%
\begingroup~

Diagonaliser dans une base orthonormale
\[ A = \begin{pmatrix} 6 & -2 & 2 \\ -2 & 5 & 0 \\ 2 & 0 & 7 \end{pmatrix} \text{ et }
B = \frac19 \begin{pmatrix} 23 & 2 & -4 \\ 2 & 29 & 2 \\ -4 & 2 & 23 \end{pmatrix}. \]
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 17}%
\hfill{\tiny 9310}%
\begingroup~

Diagonaliser les matrices
\[ \begin{pmatrix} 1 & 1 & \cdots & 1 & 1 \\ 1 & 0 & \cdots & 0 & 1 \\ \vdots & \vdots & (0) & \vdots & \vdots \\ 1 & 0 & \cdots & 0 & 1 \\ 1 & 1 & \cdots & 1 & 1 \end{pmatrix} \text{ et }
\begin{pmatrix} 2 & 1 & 0 & \cdots & \cdots & 0 \\ 1 & 2 & 1 & \ddots & (0) & \vdots \\ 0 & 1 & 2 & 1 & \ddots & \vdots \\ \vdots & \ddots & \ddots & \ddots & \ddots & 0 \\ \vdots & (0) & \ddots & 1 & 2 & 1 \\ 0 & \cdots & \cdots & 0 & 1 & 2 \end{pmatrix}. \]
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 18}%
\hfill{\tiny 1041}%
\begingroup~

Soit $p$ un projecteur de $E$ de noyau $F$ et d'image $G$.
Montrer que les conditions suivantes sont \'equivalentes:
\begin{enumerate}[label=\roman*.]
\item Pour tout $x\in E$, $p(x)$ est la projection orthogonale de $x$ sur $G$.
\item $F$ et $G$ sont orthogonaux.
\item $p$ est un endomorphisme sym\'etrique.
\end{enumerate}
On dit alors que $p$ est un \emph{projecteur orthogonal}.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 19}%
\hfill{\tiny 1347}%
\begingroup~

Soit $s$ une sym\'etrie de $E$ d'axe $F$ parall\`element \`a $G$.
Montrer que les conditions suivantes sont \'equivalentes:
\begin{enumerate}[label=\roman*.]
\item $s$ est un endomorphisme sym\'etrique.
\item $F$ et $G$ sont orthogonaux.
\end{enumerate}
On dit alors que $s$ est une \emph{sym\'etrie orthogonale}.
Notez en particulier qu'une sym\'etrie n'est pas n\'ecessairement un endomorphisme sym\'etrique.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 20}%
\hfill{\tiny 1267}%
\begingroup~

Soit $M\in\MnR$.
\begin{enumerate}
\item Montrer que $M$ est la matrice d'un projecteur orthogonal dans une base orthonormale
  si et seulement si $M^2 = M$ et $M = \T M$.
\item Montrer que $M$ est la matrice d'une sym\'etrie orthogonale dans une base orthonormale
  si et seulement si $M^2 = I_n$ et $M = \T M$.
\end{enumerate}
On pourra s'aider des exercices~18 et~19.
\endgroup

\subsubsection{Endomorphismes sym\'etriques positifs}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 21}%
\hfill{\tiny 7581}%
\begingroup~

\def\SpE{\mathscr{S}^+(E)}
\def\SppE{\mathscr{S}^{++}(E)}
Soit $u\in\SE$.
\begin{enumerate}
\item Montrer que $\Sp(u)\subset \R^+$ si et seulement si $\forall x\in E$, $\PS{u(x)}{x}\geq0$.
  Un tel endormorphisme est dit \emph{sym\'etrique positif}.
  On note $\SpE$ leur ensemble.
\item Montrer que $\Sp(u)\subset \R^+_*$ si et seulement si $\forall x\in E\setminus\acco{0_E}$, $\PS{u(x)}{x} > 0$.
  Un tel endormorphisme est dit \emph{sym\'etrique d\'efini positif}.
  On note $\SppE$ leur ensemble.
\item Montrer que $\SppE = \SpE\cap\GLE$.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 22}%
\hfill{\tiny 2508}%
\begingroup~

Soit $A\in\SnR$.
\begin{enumerate}
\item Montrer que les conditions suivantes sont \'equivalentes:
  \begin{enumerate}[label=\roman*.]
  \item $\forall X\in\mathrm{M}_{n,1}(\R)$, $\T{X} A X\geq0$
  \item $\Sp A\subset \R^+$
  \end{enumerate}
  Une matrice sym\'etrique v\'erifiant ces conditions est dite positive.
  L'ensemble des matrices sym\'etriques positives se note $\SnRp$.
\item Montrer que les conditions suivantes sont \'equivalentes:
  \begin{enumerate}[label=\roman*.]
  \item $\forall X\in\mathrm{M}_{n,1}(\R)\setminus\acco0$, $\T{X} A X > 0$
  \item $\Sp A\subset \R^+_*$
  \item $A\in\SnRp\cap\GLnR$
  \end{enumerate}
  Une matrice sym\'etrique v\'erifiant ces conditions est dite d\'efinie positive.
  L'ensemble des matrices d\'efinies sym\'etriques positives se note $\SnRpp$.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/3071.pdf}{Exercice 23}}%
\hfill{\tiny 3071}%
\begingroup~

La matrice $A = \begin{pmatrix} 4 & 1 & 1 \\ 1 & 4 & 1 \\ 1 & 1 & 4 \end{pmatrix}$
est-elle une matrice sym\'etrique d\'efinie positive?
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 24}%
\hfill{\tiny 0409}%
\begingroup~

Soit $A\in\MnR$. Montrer que $A$ est sym\'etrique d\'efinie positive
si et seulement si il existe $M$ inversible telle que $A = \T{M} M$.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 25}%
\hfill{\tiny 9475}%
\begingroup~

Soit $A\in\SnRp$.
Montrer qu'il existe une unique matrice $B\in\SnRp$ telle que $A = B^2$.
Pour l'unicit\'e, on pourra se ramener \`a des endomorphismes.

Calculer $B$ lorsque $A = \begin{pmatrix} 1 & 2 \\ 2 & 5 \end{pmatrix}$.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 26 (diagonalisation simultan\'ee)}%
\hfill{\tiny 5242}%
\begingroup~

Soit $A\in\SnRpp$ et $B\in\SnR$.
Le but de cet exercice est de d\'emontrer le th\'eor\`eme de r\'eduction simultan\'ee,
qui affirme qu'il existe $(M,D)\in\GLnR\times\DnR$ telles que
$A = \T{M} M$ et $B = \T{M} D M$.\begin{enumerate}
\item Montrer qu'il existe $P\in\OnR$ et $E\in\DnR$ telles que $A = P E P^{-1}$.
\item Montrer qu'il existe $F\in\DnR$ telle que $E = F^2$.
\item On pose $B' = F^{-1} P^{-1} B P F^{-1}$.
  Montrer que $B'\in\SnR$, et en d\'eduire qu'il existe $Q\in\OnR$
  et $D\in\DnR$ telles que $B' = QDQ^{-1}$.
\item On pose $M = Q^{-1} F P^{-1}$. Calculer $\T{M} M$ et $\T{M} D M$. Conclure.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 27}%
\hfill{\tiny 8961}%
\begingroup~

Soit $A\in\SnRpp$ et $B\in\SnRp$.
Montrer que $\det(A+B)\geq\det A + \det B$.

On pourra utiliser le r\'esultat de l'exercice pr\'ec\'edent.
\endgroup

\subsubsection{Endomorphismes orthogonaux}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 28}%
\hfill{\tiny 5196}%
\begingroup~

Les projecteurs orthogonaux sont-ils des endomorphismes orthogonaux?
M\^eme question pour les sym\'etries orthogonales.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 29}%
\hfill{\tiny 7277}%
\begingroup~

Quels sont les endomorphismes orthogonaux diagonalisables?
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/5990.pdf}{Exercice 30}}%
\hfill{\tiny 5990}%
\begingroup~

Soit $A\in\OnR$.
Montrer que $\forall \lambda\in\Sp_\C(A)$, on a $\abs{\lambda} = 1$.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 31}%
\hfill{\tiny 9035}%
\begingroup~

Quels sont les endomorphismes \`a la fois sym\'etriques et orthogonaux?
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/7214.pdf}{Exercice 32}}%
\hfill{\tiny 7214}%
\begingroup~

Soit $A = (a_{i,j}) \in{} \OnR$.
Montrer que \[ \Abs{ \sum_{i=1}^n \sum_{j=1}^n a_{i,j} } \leq{} n. \]
Cas d'\'egalit\'e?
\endgroup

\subsubsection{Adjoint}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 33 (facile, mais important)}%
\hfill{\tiny 3328}%
\begingroup~

Soit $E$ euclidien, $(x,y)\in E^2$, $\B$ une base de $E$,
$X = \Coords_\B(x)$ et
$Y = \Coords_\B(y)$.\begin{enumerate}
\item Si $\B$ est une base orthonormale, montrer que $\PS xy = \T XY$.
\item Dans le cas g\'en\'eral,
  montrer qu'il existe une matrice $A\in\SnR$ telle que $\PS xy = \T XAY$.
  Expliciter $A$.
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/7959.pdf}{Exercice 34}}%
\hfill{\tiny 7959}%
\begingroup~

Soit $E$ euclidien, $u\in\LE$.
\begin{enumerate}
\item Soit $u\in\LE$, $\B$ une base orthonormale de $E$ et $A = \Mat_\B(u)$.
  On d\'efinit $v\in\LE$ par la relation $\Mat_\B(v) = \T A$.
  Montrer que
  \[ \forall(x,y)\in E^2 \+ \PS{u(x)}{y} = \PS{x}{v(y)}. \]
\item En d\'eduire que pour tout $u\in\LE$,
  il existe un unique $v\in\LE$ tel que
  \[ \forall(x,y)\in E^2, \quad \PS{u(x)}{y} = \PS{x}{v(y)} \]
  $v$ s'appelle l'\emph{adjoint} de $u$ et se note $v=u^*$.
\item V\'erifier que dans toute base orthonormale $\B'$, on a
  \[ \Mat_{\B'}(u^*) = \T{\Mat_{\B'}(u)}. \]
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 35}%
\hfill{\tiny 7129}%
\begingroup~

Soit $E$ euclidien et $u\in\LE$.\begin{enumerate}
\item Montrer que $u\in\SE$ si et seulement si $u^* = u$.
\item Montrer que $u\in \OE$ si et seulement si $u$ est inversible d'inverse $u^*$.
\end{enumerate}
\endgroup

\subsubsection{Divers}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 36}%
\hfill{\tiny 7533}%
\begingroup~

Soit $E$ un espace euclidien de dimension $n$,
$\B$ une base orthonormale de $E$ et
$\nUplet x1n$ une famille de vecteurs de $E$.
Le but de cet exercice est de montrer l'in\'egalit\'e suivante:
\[ \Abs{ \det_\B \nUplet x1n }
\leq{} \Norm{x_1}\cdot\Norm{x_2}\cdot\cdots\cdot\Norm{x_n} \]
\begin{enumerate}
\item Montrer que le r\'esultat est vrai si $\nUplet x1n$ n'est pas libre.
\item On suppose d\'esormais $\nUplet x1n$ libre.
  On utilise le proc\'ed\'e de Schmidt,
  et on obtient $\nUplet y1n$ orthogonale et $\nUplet z1n$ orthonormale.
  Montrer par r\'ecurrence sur $k$ que
  \[ \det_\B \nUplet x1n
  = \det_\B (y_1, \cdots, y_k, x_{k+1}, \cdots x_n) \]
\item Conclure.
\end{enumerate}

% -----------------------------------------------------------------------------
\endgroup

\subsection{Un peu de g\'eom\'etrie}

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 37}%
\hfill{\tiny 6314}%
\begingroup~

Compl\'eter la matrice $A = \frac1\star \begin{pmatrix} 6 & 3 & \star \\ -2 & 6 & \star \\ 3 & \star & \star \end{pmatrix}$
en une matrice orthogonale positive,
et d\'ecrire la transformation g\'eom\'etrique associ\'ee \`a $A$.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 38}%
\hfill{\tiny 2621}%
\begingroup~

Reconna\^itre les endomorphismes de $\R^3$ muni de sa structure euclidienne
usuelle canoniquement associ\'es aux matrices suivantes:
\[ \frac13\begin{pmatrix} -2 & -1 & 2 \\ 2 & -2 & 1 \\ 1 & 2 & 2 \end{pmatrix},
  \frac19\begin{pmatrix} -7 & -4 & 4 \\ 4 & -8 & -1 \\ -4 & -1 & -8 \end{pmatrix},
\begin{pmatrix} 8 & 1 & 4 \\ -4 & 4 & 7 \\ 1 & 8 & -4 \end{pmatrix}. \]
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 39}%
\hfill{\tiny 8563}%
\begingroup~

D\'eterminer la matrice de la rotation $r$ de $\R^3$ dans une base orthonorm\'ee
$(i, j, k)$ telle que $r(u) = u$
avec $u = i - j + k$ et $r(i) = k$.
Donner son angle de rotation.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/1190.pdf}{Exercice 40}}%
\hfill{\tiny 1190}%
\begingroup~

On consid\`ere l'endomorphisme $f$ de $\R^3$ de matrice dans la base canonique
\[ A = \begin{pmatrix} a^2 & ab-c & ac+b \\ ab+c & b^2 & bc-a \\ ac-b & bc+a & c^2 \end{pmatrix} \]
o\`u $(a,b,c)\in \R^3$.
D\'eterminer $a,b,c$ de sorte que $f$ soit une isom\'etrie, et la pr\'eciser.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 41}%
\hfill{\tiny 5960}%
\begingroup~

Reconna\^itre les endomorphismes de $\R^3$ d\'efinis par
\begin{enumerate}
\item $\left\{ \begin{alignedat}{4}
        3x' & {}={} & 2x  & {}+{} & 2y & {}+{} & z  \\
        3y' & {}={} & -2x & {}+{} & y  & {}+{} & 2z \\
        3z' & {}={} & x   & {}-{} & 2y & {}+{} & 2z
  \end{alignedat} \right.$
\item $\left\{ \begin{alignedat}{4}
        4x' & {}={} & -2x      & {}-{} & y\sqrt6 & {}+{} & z\sqrt6 \\
        4y' & {}={} & x\sqrt6  & {}+{} & y       & {}+{} & 3z      \\
        4z' & {}={} & -x\sqrt6 & {}+{} & 3y      & {}+{} & z
  \end{alignedat} \right.$
\item $\left\{ \begin{alignedat}{4}
        3x' & {}={} & x  & {}+{} & 2y & {}+{} & 2z \\
        3y' & {}={} & 2x & {}+{} & y  & {}-{} & 2z \\
        3z' & {}={} & 2x & {}-{} & 2y & {}+{} & z
  \end{alignedat} \right.$
\item $\left\{ \begin{alignedat}{4}
        4x' & {}={} & -x      & {}+{} & 3y      & {}-{} & z\sqrt6       \\
        4y' & {}={} & 3x      & {}-{} & y       & {}-{} & z\sqrt6        \\
        4z' & {}={} & x\sqrt6 & {}+{} & y\sqrt6 & {}+{} & 2z
  \end{alignedat} \right.$
\end{enumerate}
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{Exercice 42}%
\hfill{\tiny 8649}%
\begingroup~

Soit $\DS A = \begin{pmatrix} a & b & c \\ c & a & b \\ b & c & a \end{pmatrix}$.
Montrer que A est une matrice orthogonale positive
si et seulement si $a$, $b$ et $c$ son les racines du polyn\^ome
$P(X) = X^3 - X^2 + k$, o\`u $0\leq k\leq\frac{4}{27}$.
% En posant $k = \frac{4}{27} \sin^2\theta$,
D\'eterminer alors l'axe et l'angle de la rotation associ\'ee \`a $A$.
\endgroup

% -----------------------------------------------------------------------------
\par\pagebreak[1]\par
\paragraph{\href{https://psi.miomio.fr/exo/8162.pdf}{Exercice 43}}%
\hfill{\tiny 8162}%
\begingroup~

Soit $E$ un espace euclidien, $H$ et $K$ deux hyperplans de $E$.
On note $s_H$ la sym\'etrie orthogonale par rapport \`a $H$, et de m\^eme pour $s_K$.
Montrer que $s_H$ et $s_K$ commutent si et seulement si $H = K$ ou $\Orth{H} \subset{} K$.
\endgroup

\end{document}
