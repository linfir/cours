\documentclass{yann}
\usepackage{tikz}
\usetikzlibrary{matrix,calc}

\newcommand\sqn[2]{\ccro{1,#1}Ã—\ccro{1,#2}}
\newcommand\MM[1]{\M{M}{#1}{ğ•‚}}
\newcommand\BC{\mathscr{C}}

\begin{document}
\title{AlgÃ¨bre linÃ©aire 2}
\maketitle

\Para{Notations}
$ğ•‚$ dÃ©signe un corps;
toutes les matrices considÃ©rÃ©es seront Ã  coefficients dans $ğ•‚$;
tous les Â£evs. considÃ©rÃ©s seront des Â£Kevdfs..

% ---------------------------------------------------------------------------
\section{Matrice}

% ---------------------------------------------------------------------------
\subsection{DÃ©finition algÃ©brique}

\Para{DÃ©finition}

Soit $(n,p)âˆˆâ„•_*^2$.
Une \emph{matrice} de type $(n,p)$ est une application de $\sqn np$ dans $ğ•‚$.
L'ensemble des matrices de type $(n,p)$ est notÃ© $\MM{n,p}$.
La matrice $M \colon (i,j) \mapsto m_{i,j}$ est notÃ©e $M = \pa{ m_{i,j} }_{\substack{1â‰¤iâ‰¤n\\1â‰¤jâ‰¤p}}$.

\Para{OpÃ©rations}

\begin{enumerate}
\item
  Si $A$ et $B$ sont deux matrices de type $(n,p)$,
  on dÃ©finit la matrice $C = A+B$ de type $(n,p)$
  par $c_{i,j} = a_{i,j} + b_{i,j}$
  pour tout $(i,j)âˆˆ\sqn np$.
\item
  Si $Î»$ est un scalaire et $A$ une matrice de type $(n,p)$,
  on dÃ©finit la matrice $B = Î»A$ de type $(n,p)$
  par $b_{i,j} = Î»a_{i,j}$ pour tout $(i,j)âˆˆ\sqn np$.
\item
  Si $A$ est une matrice de type $(n,p)$ et $B$ est une matrice de type $(p,q)$,
  on dÃ©finit la matrice $C = A Ã— B$ de type $(n,q)$
  par \[ c_{i,j} = âˆ‘_{k=1}^p a_{i,k} b_{k,j} \] pour tout $(i,j)âˆˆ\sqn nq$.
\end{enumerate}

\Para{PropriÃ©tÃ©s}

\begin{enumerate}
\item
  $(\MM{n,p},+,â‹…)$ est un Â£ev..
\item
  Si $A âˆˆ \MM{n,p}$, $B âˆˆ \MM{p,q}$ et $C âˆˆ \MM{q,r}$, alors
  les produits suivants sont bien dÃ©finis
  et $(A Ã— B) Ã— C = A Ã— (B Ã— C)$.
\item
  Si $Î»âˆˆ ğ•‚$, $A âˆˆ \MM{n,p}$ et $B âˆˆ \MM{p,q}$,
  alors $(Î»A) Ã— B = A Ã— (Î»B) = Î»(A Ã— B)$.
\item
  Si $A âˆˆ \MM{n,p}$, $B âˆˆ \MM{n,p}$ et $C âˆˆ \MM{p,q}$,
  alors les sommes et les produits suivants sont bien dÃ©finis
  et $(A + B) Ã— C = AÃ—C + BÃ—C$.
\item
  Si $A âˆˆ \MM{n,p}$, $B âˆˆ \MM{p,q}$ et $C âˆˆ \MM{p,q}$,
  alors les sommes et les produits suivants sont bien dÃ©finis
  et $A Ã— (B + C) = AÃ—B + AÃ—C$.
\end{enumerate}

\Para{Remarque}

En gÃ©nÃ©ral $A Ã— B â‰  B Ã— A$, mÃªme dans le cas de deux matrices $(n,n)$.

% ---------------------------------------------------------------------------
\subsection{Lien avec les Â£evs.}

\Para{DÃ©finition: coordonnÃ©es d'un vecteur}

Soit $E$ un Â£Kev. de dimension $n$ et $\B = \nUplet e1n$ une base de $E$.
On sait que tout vecteur $xâˆˆE$ se dÃ©compose de faÃ§on unique sous la forme
$x = Î¾_1 e_1 + \dots + Î¾_n e_n$ oÃ¹ $\nUplet Î¾1n âˆˆ ğ•‚^n$
On appelle coordonnÃ©es de $x$ dans la base $E$ le $n$-uplet
\[ \Coords_\B(x) = \nUplet Î¾1n âˆˆğ•‚^n. \]

\Para{Remarque}

On identifiera frÃ©quemment les $n$-uplets avec les matrices colonnes;
cela est lÃ©gitime car l'application
\[ \Fonction{Ï•}{ğ•‚^n}{\MM{n,1}}{\nUpletÎ¾1n}{\Matrix{Î¾_1;\vdots;Î¾_n}} \]
est un isomorphisme.

\Para{DÃ©finition: matrice d'un endomorphisme}

Soit $E$ et $F$ deux Â£evdfs., $\B = \nUplet e1p$ une base de $E$ et $\B' = \nUplet f1n$ une base de $F$.
Pour tout $jâˆˆ\ccro{1,p}$, le vecteur $u(e_j)$ se dÃ©compose dans la base $\B'$:
\[ u(e_j) = âˆ‘_{i=1}^n a_{i,j} f_i. \]
On appelle \emph{matrice de l'endomorphisme $u$} la matrice suivante, de type $(n,p)$:
\[ \Mat(u,\B \to \B') = \Mat_{\B\to\B'}(u) = \bigPa{ a_{i,j} }_{\substack{1â‰¤iâ‰¤n\\1â‰¤jâ‰¤p}}. \]
\begin{center}
  \begin{tikzpicture}[
      every left delimiter/.style={xshift=0.75em},
      every right delimiter/.style={xshift=-0.75em},
      dots/.style={
        line width=1pt,
        line cap=round,
        dash pattern=on 0pt off 5pt,
        shorten >=.1cm,
    shorten <=.1cm}]
    \matrix (M) [
      matrix of nodes,
      left delimiter=(,
      right delimiter=),
    ]{
      \node (A) {$a_{1,1}$}; &[1.1cm] \node (B) {$a_{1,p}$}; \\[1.1cm]
      \node (C) {$a_{n,1}$}; &        \node (D) {$a_{n,p}$}; \\
    };

    \draw (M.west) node[left] {$\Mat\limits_{\B\to\B'}(u)=$};
    \draw [dots] (A.east)  -- (B.west);
    \draw [dots] (C.east)  -- (D.west);
    \draw [dots] (A.south) -- (C.north);
    \draw [dots] (B.south) -- (D.north);
    \draw (A) [yshift=0.7cm] node (E) {$u(e_1)$};
    \draw (B) [yshift=0.7cm] node (F) {$u(e_p)$};
    \draw (B) [xshift=1cm]   node (G) {$f_1$};
    \draw (D) [xshift=1cm]   node (H) {$f_n$};
    \draw [dots] (E.east)  -- (F.west);
    \draw [dots] (G.south) -- (H.north);
  \end{tikzpicture}
\end{center}
Dans le cas oÃ¹ $E=F$ et $\B=\B'$, on la note $\Mat(u,\B)$ ou $\Mat_\B(u)$.

\Para{DÃ©finition}

Inversement, si l'on se donne une matrice $M âˆˆ \MM{n,p}$,
on peut dÃ©finir une application linÃ©aire, dite \emph{canoniquement associÃ©e Ã  $M$}, par
\[ \Fonction{f_M}{ğ•‚^p}{ğ•‚^n}{x}{Mx} \]
oÃ¹ l'on identifie $ğ•‚^n$ et $\MM{n,1}$ ainsi que $ğ•‚^p$ et $\MM{p,1}$.

Si l'on note $\B$ la base canonique de $ğ•‚^p$ et $\B'$ la base canonique de $ğ•‚^n$,
on vÃ©rifie facilement que
\[ \Mat(f_M, \B \to \B') = M. \]

\Para{ThÃ©orÃ¨me}

Soit $E$ et $F$ deux Â£evdfs. munis de bases $\B$ et $\B'$.
Soit $\Fn uEF$ une application linÃ©aire et $x$ un vecteur de $E$.
Alors \[ \Coords_{\B'}\bigPa{u(x)} = \Mat_{\B\to\B'}(u) Ã— \Coords_\B(x). \]

\Para{ThÃ©orÃ¨me}

Soit $E$ et $F$ deux Â£evdfs. munis de bases $\B$ et $\B'$.
L'application
\[ \Fonction{}{\mathscr{L}(E,F)}{\MM{n,p}}{u}{\Mat_{\B\to\B'}(u)} \]
est linÃ©aire et bijective, autrement dit un isomorphisme.

\Para{ThÃ©orÃ¨me}

Soit $E$, $F$, $G$ trois Â£evdfs. munis des bases respectives $\B$, $\B'$ et $\B''$.
Soit $\Fn uEF$ et $\Fn vFG$ deux applications linÃ©aires.
Alors
\[ \Mat_{\B\to\B''}(vâ—¦u) = \Mat_{\B'\to\B''}(v) Ã—\Mat_{\B\to\B'}(u). \]

% ---------------------------------------------------------------------------
\subsection{Formules de changement de base}

\Para{DÃ©finition}

Soit $E$ un Â£evdf., $\B$ et $\B'$ deux bases de $E$.
On appelle \emph{matrice de passage} de $\B$ Ã  $\B'$ la matrice
\[ \Pass(\B\to\B') = \Mat_{\B'\to\B}(\Id_E). \]

De faÃ§on plus explicite, notons $\B = \nUplet e1n$,
$\B' = \nUplet f1n$ et $\Pass(\B\to\B') = \bigPa{ a_{i,j} }$.
Dans ce cas, on a
\[ âˆ€j âˆˆ \ccro{1,n} \+ f_j = âˆ‘_{i=1}^n a_{i,j} e_i. \]
Ainsi,
\begin{center}
  \begin{tikzpicture}[
      every left delimiter/.style={xshift=0.75em},
      every right delimiter/.style={xshift=-0.75em},
      dots/.style={
        line width=1pt,
        line cap=round,
        dash pattern=on 0pt off 5pt,
        shorten >=.1cm,
    shorten <=.1cm}]
    \matrix (M) [
      matrix of nodes,
      left delimiter=(,
      right delimiter=),
    ]{
      \node (A) {$a_{1,1}$}; &[1.1cm] \node (B) {$a_{1,n}$}; \\[1.1cm]
      \node (C) {$a_{n,1}$}; &        \node (D) {$a_{n,n}$}; \\
    };

    \draw (M.west) node[left] {$\Pass(\B\to\B')=$};
    \draw [dots] (A.east)  -- (B.west);
    \draw [dots] (C.east)  -- (D.west);
    \draw [dots] (A.south) -- (C.north);
    \draw [dots] (B.south) -- (D.north);
    \draw (A) [yshift=0.7cm] node (E) {$f_1$};
    \draw (B) [yshift=0.7cm] node (F) {$f_n$};
    \draw (B) [xshift=1cm]   node (G) {$e_1$};
    \draw (D) [xshift=1cm]   node (H) {$e_n$};
    \draw [dots] (E.east)  -- (F.west);
    \draw [dots] (G.south) -- (H.north);
  \end{tikzpicture}
\end{center}

\Para{Proposition}

Soit $E$ un Â£evdf. et $\B$, $\B'$ et $\B''$ trois bases de $E$.
Alors
\begin{enumerate}
\item
  $\Pass(\B \to \B') Ã— \Pass(\B' \to \B'') = \Pass(\B \to \B'')$;
\item
  $\Pass(\B \to \B')$ est inversible, et son inverse est $\Pass(\B' \to \B)$.
\end{enumerate}


\Para{Proposition}

Soit $E$ un Â£evdf., $\B$ et $\B'$ deux bases de $E$.
Soit $x$ un vecteur de $E$.
Alors \[ X = PX'\]
oÃ¹
\begin{itemize}
\item $P = \Pass(\B \to \B')$,
\item $X = \Coords_\B(x)$,
\item $X' = \Coords_{\B'}(x)$.
\end{itemize}

\Para{Proposition}

Soit $E$ un Â£evdf. muni de deux bases $\B$ et $\B'$.
Soit $F$ un Â£evdf. muni de deux bases $\BC$ et $\BC'$.
Soit $\Fn uEF$ une application linÃ©aire.
Alors on a \[ A' = Q^{-1} A P \]
oÃ¹
\begin{itemize}
\item $P = \Pass(\B \to \B')$,
\item $Q = \Pass(\BC \to \BC')$,
\item $A = \Mat_{\B \to \BC}(u)$,
\item $A' = \Mat_{\B' \to \BC'}(u)$.
\end{itemize}

\Para{Corollaire}

Soit $E$ un Â£evdf. muni de deux bases $\B$ et $\B'$.
Soit $u$ un endomorphisme de $E$.
Alors on a \[ A' = P^{-1} A P \]
oÃ¹
\begin{itemize}
\item $P = \Pass(\B \to \B')$,
\item $A = \Mat_{\B}(u)$,
\item $A' = \Mat_{\B'}(u)$.
\end{itemize}

% ------------------------------------------------------------------------------
\section{Matrices carrÃ©s}

\subsection{Matrices inversibles}

%\Para{DÃ©finition}

La \emph{matrice identitÃ©} de taille $n$ est la matrice
$I_n = \bigPa{ Î´_{i,j} } âˆˆ \MnK$.

\Para{ThÃ©orÃ¨me}

Soit $A$ et $B$ deux matrices carrÃ©es de taille $n$.
On suppose que $AB = I_n$.
Alors $BA = I_n$.

% ---------------------------------------------------------------------------
\subsection{Similitude}

\Para{DÃ©finition}

Soit $A$ et $B$ deux matrices carrÃ©es de $\MnK$.
On dit que $A$ et $B$ sont \emph{semblables}
Â£ssil. existe une matrice inversible $Pâˆˆ\GLnK$
telle que \[ B = P^{-1} A P. \]


\Para{PropriÃ©tÃ©s}

Il s'agit d'une relation d'Ã©quivalence, Â£cad.:
\begin{enumerate}
\item $A \sim A$;
\item si $A \sim B$, alors $B \sim A$;
\item si $A \sim B$ et $B \sim C$, alors $A \sim C$.
\end{enumerate}

\Para{Proposition}

Soit $u$ un endomorphisme de $E$.
Les matrices $\Mat_\B(u)$ et $\Mat_{\B'}(u)$ sont semblables.

\Para{Proposition}

Soit $A$ et $B$ deux matrices.
Soit $E$ un Â£ev. de dimension $n$ et $\B$ une base de $E$.
Notons $u$ l'unique endomorphisme de $E$ tel que $\Mat_\B(u) = A$.
Alors $A$ et $B$ sont semblables Â£ssi. il existe une base $\B'$ de $E$ telle que $\Mat_{\B'}(u) = B$.

% ------------------------------------------------------------------------------
\subsection{Trace}

\Para{DÃ©finition}

Soit $A = \bigl(a_{i,j}\bigr)_{1â‰¤i,jâ‰¤n}âˆˆ\MnK$ une matrice carrÃ©e.
La \emph{trace} de la $A$ est le scalaire
\[ \Tr(A) = âˆ‘_{k=1}^n a_{k,k}. \]

\Para{PropriÃ©tÃ©s}

\begin{enumerate}
\item La trace est une application linÃ©aire de $\MnK$ dans $ğ•‚$.
  Autrement dit, pour toutes matrices $(A,B)âˆˆ\MnK^2$ et pour tous $(Î»,Î¼)âˆˆğ•‚^2$, on a
  \[ \Tr(Î»A + Î¼B) = Î»\Tr(A) + Î¼\Tr(B). \]
\item Pour toutes matrices $(A,B) âˆˆ\MnK^2$, on a
  \[ \Tr(AB) = \Tr(BA). \]
\item Si $A$ et $B$ sont deux matrices semblables de $\MnK$, alors elles ont la mÃªme trace.
\end{enumerate}

\Para{Attention}

En gÃ©nÃ©ral, $\Tr(ABC)â‰ \Tr(ACB)$.

\Para{DÃ©finition}[trace d'un endomorphisme]

Soit $E$ un $ğ•‚$-espace vectoriel de dimension finie et $u$ un endomorphisme de $E$.
Soit $\B$ une base de $E$ et $M$ la matrice de $u$ dans la base $\B$.
La quantitÃ© $\Tr(M)$ ne dÃ©pendant pas du choix de la base $\B$, mais seulement de $u$, on l'appelle \emph{trace} de l'endomorphisme $u$ et on note $\Tr(u) = \Tr(M)$.

\Para{PropriÃ©tÃ©s}

\begin{enumerate}
\item La trace est une application linÃ©aire de $\LE$ dans $ğ•‚$.
\item Si $u$ et $v$ sont deux endomorphismes de $E$, alors $\Tr(uâ—¦v) = \Tr(vâ—¦u)$.
\end{enumerate}

% ---------------------------------------------------------------------------
\subsection{DÃ©terminants}

\Para{ThÃ©orÃ¨me}

Soit $nâˆˆ\Ns$.
Il existe une unique application $\Fn{d}{\MnK}{ğ•‚}$ vÃ©rifiant les propriÃ©tÃ©s suivantes:
\begin{enumerate}
\item
  $d(I_n) = 1$;
\item
  $d(A) = 0$ si deux colonnes de $A$ sont Ã©gales;
\item
  Si on fixe $n-1$ colonnes de $A$, l'application qui Ã  la derniÃ¨re colonne associe $d(A)$ est linÃ©aire.

  Plus prÃ©cisÃ©ment, soit $A$, $B$ et $C$ des matrices de $\MnK$.
  pour $1â‰¤jâ‰¤n$, on note $A_j$, $B_j$ et $C_j$ les $j$-Ã¨me colonnes de $A$, $B$ et $C$ respectivement.
  On suppose que
  \begin{itemize}
  \item $A_k = Î»B_k + Î¼C_k$ oÃ¹ $k âˆˆ \ccro{1,n}$ et $(Î»,Î¼)âˆˆğ•‚^2$;
  \item pour tout $j âˆˆ \ccro{1,n} âˆ– \acco{k}$, $A_j = B_j = C_j$.
  \end{itemize}
  Alors $d(A) = Î»d(B) + Î¼d(C)$.
\end{enumerate}

Cette application $d$ vÃ©rifie alors automatiquement les propriÃ©tÃ©s suivantes:
\begin{enumerate}[resume]
\item
  $d(B) = -d(A)$ si $B$ se dÃ©duit de $A$ en Ã©changeant deux colonnes;
\item
  $d(B) = d(A)$ si $B$ se dÃ©duit de $A$ par une opÃ©ration du type $C_i \leftarrow C_i + âˆ‘_{kâ‰ i} Î±_k C_k$;
\item
  $d(B) = Î»d(A)$ si $B$ se dÃ©duit de $A$ par une opÃ©ration du type $C_i \leftarrow Î»C_i$;
\item
  $d(A) = d(\T A)$ pour toute matrice $Aâˆˆ\MnK$;
\item
  dans toutes les propriÃ©tÃ©s prÃ©cÃ©dentes, on peut remplacer \enquote{colonnes} par \enquote{lignes};
\item
  $d(AB) = d(A) d(B)$ pour toutes les matrices $(A,B)âˆˆ\MnK^2$;
\item
  $d(A) â‰  0$ Â£ssi. $A$ est inversible.
\end{enumerate}

% ---------------------------------------------------------------------------
\subsubsection{DÃ©terminant de Vandermonde}

\Para{DÃ©finitions}

Soit $\nUplet a1n âˆˆğ•‚^n$.
La \emph{matrice de Vandermonde} associÃ©e Ã  $\nUplet a1n$ est
\[ M = \begin{pmatrix}
    1 &  1 &  1 &  \dots &  1  \\
    a_1 &  a_2 &  a_3 &  \dots &  a_n  \\
    a_1^2 &  a_2^2 &  a_3^2 &  \dots &  a_n^2  \\
    \vdots &  \vdots &  \vdots &   &  \vdots  \\
a_1^{n-1} &  a_2^{n-1} &  a_3^{n-1} &  \dots &  a_n^{n-1}  \end{pmatrix}. \]
Le \emph{dÃ©terminant de Vandermonde} $V \nUplet a1n$ est le dÃ©terminant de la matrice de Vandermonde ci-dessus.

\Para{ThÃ©orÃ¨me}

Avec les mÃªmes notations,
\[ V\nUplet a1n = âˆ_{1â‰¤i < jâ‰¤n} (a_j - a_i). \]
En particulier,
\begin{itemize}
\item $V(a) = 1$,
\item $V(a,b) = b-a$,
\item $V(a,b,c) = (b-a)(c-a)(c-b)$.
\end{itemize}

\Para{Corollaire}

La matrice de Vandermonde associÃ©e Ã  $\nUplet a1n$ est inversible si et seulement si les nombres $\nUplet a1n$ sont deux Ã  deux distincts.

% ---------------------------------------------------------------------------
\section{Matrices par blocs}

\Para{DÃ©finition}

Soit $(s,t) âˆˆ(\Ns)^2$, $(n_1, \dots, n_s) âˆˆ(\Ns)^s$ et $(p_1, \dots, p_t) âˆˆ(\Ns)^t$ des entiers naturels non nuls.
On pose:
\begin{itemize}
\item pour tout $k âˆˆ\Dcro{0,s}$, $Ïƒ_k = âˆ‘_{i=1}^k n_i$,
\item pour tout $l âˆˆ\Dcro{0,t}$, $Ï„_l = âˆ‘_{j=1}^l p_j$,
\item $n = n_1 + \dots + n_s = Ïƒ_s$,
\item $p = p_1 + \dots + p_t = Ï„_t$.
\end{itemize}

Soit $Aâˆˆ\mathrm{M}_{n,p}(ğ•‚) = \bigl( a_{ij} \bigr)_{\substack{1â‰¤iâ‰¤n \\ 1â‰¤jâ‰¤p}}$ une matrice.
Sa dÃ©composition par blocs suivant le dÃ©coupage $\nUplet n1s$ pour les lignes et $\nUplet p1t$ pour les colonnes est
\begin{center}
  \begin{tikzpicture}[
      dots/.style={
        line width=1pt,
        line cap=round,
        dash pattern=on 0pt off 5pt,
        shorten >=.1cm,
    shorten <=.1cm}]
    \matrix[
      matrix of nodes,
      left delimiter=(,
      right delimiter=),
    ]{
      \node (A) {$A_{1,1}$}; &[1.1cm] \node (B) {$A_{1,t}$}; \\[1.1cm]
      \node (C) {$A_{s,1}$}; &        \node (D) {$A_{s,t}$}; \\
    };

    \draw [dots] (A.east)  -- (B.west);
    \draw [dots] (C.east)  -- (D.west);
    \draw [dots] (A.south) -- (C.north);
    \draw [dots] (B.south) -- (D.north);

    \draw [<->]  ([xshift=1cm]B.north east) -- node [right] {$n_1$} ([xshift=1cm]B.south east);
    \draw [<->]  ([xshift=1cm]D.north east) -- node [right] {$n_s$} ([xshift=1cm]D.south east);
    \draw [dots] ([xshift=1cm]B.south east) -- ([xshift=1cm]D.north east);
    \draw [<->]  ([xshift=1.75cm]B.north east) -- node [right] {$n$} ([xshift=1.75cm]D.south east);

    \draw [<->]  ([yshift=-0.5cm]C.south west) -- node [below] {$p_1$}([yshift=-0.5cm]C.south east);
    \draw [<->]  ([yshift=-0.5cm]D.south west) -- node [below] {$p_t$}([yshift=-0.5cm]D.south east);
    \draw [dots] ([yshift=-0.5cm]C.south east) -- ([yshift=-0.5cm]D.south west);
    \draw [<->]  ([yshift=-1.1cm]C.south west) -- node [below] {$p$} ([yshift=-1.1cm]D.south east);

    \node[xshift=-0.9cm] at ($(A.west)!0.5!(C.west)$) { $A =$ };
  \end{tikzpicture}
\end{center}
oÃ¹ pour tout $kâˆˆ\Dcro{1,s}$ et $lâˆˆ\Dcro{1,t}$, on a
\[ A_{k,l} = \begin{pmatrix}
    a_{1+Ïƒ_{k-1},1+Ï„_{l-1}}  &  \dots &  a_{1+Ïƒ_{k-1},Ï„_l}  \\
    \vdots &   &  \vdots  \\
    a_{Ïƒ_k, 1+Ï„_{l-1}} &  \dots &  a_{Ïƒ_k,Ï„_l}
\end{pmatrix} âˆˆ\mathrm{M}_{n_k,q_l}(ğ•‚). \]

\Para{Proposition}[addition par blocs]

Soit $A$ et $B$ deux matrices de $\mathrm{M}_{n,p}(ğ•‚)$ exprimÃ©es par blocs selon les mÃªmes dÃ©coupages. Soit $(Î»,Î¼)âˆˆğ•‚^2$.
Alors la matrice $Î»A + Î¼B$ s'exprime par blocs selon les mÃªmes dÃ©coupages que $A$ et $B$, et les blocs s'obtiennent en combinant les blocs situÃ©s aux mÃªmes places.

\Para{ThÃ©orÃ¨me}[produit par blocs]

Soit $Aâˆˆ\mathrm{M}_{n,p}(ğ•‚)$ et $Bâˆˆ\mathrm{M}_{p,q}(ğ•‚)$.
On suppose que $A$ a une dÃ©compositon par blocs suivant le dÃ©coupage $\nUplet n1s$ pour les lignes et $\nUplet p1t$ pour les colonnes.
On suppose que $B$ a une dÃ©composition par blocs suivant le dÃ©coupage $\nUplet p1t$ pour les lignes et $\nUplet q1u$ pour les colonnes.

Alors le produit $C = ABâˆˆ\mathrm{M}_{n,q}(ğ•‚)$ admet une dÃ©composition par blocs suivant le dÃ©coupage $\nUplet n1s$ pour les lignes et $\nUplet q1u$ pour les colonnes
\[ C = \begin{pmatrix} C_{1,1} &  \dots &  C_{1,u}  \\  \vdots &   &  \vdots  \\  C_{s,1} &  \dots &  C_{s,u} \end{pmatrix} \]
oÃ¹ pour tous $iâˆˆ\Dcro{1,s}$ et $jâˆˆ\Dcro{1,u}$,
\[ C_{i,j} = âˆ‘_{k=1}^t A_{i,k} B_{k,j} \]

\Para{Remarque}

Le cas qui nous intÃ©ressera le plus frÃ©quemment est celui des matrices carrÃ©es ayant le mÃªme dÃ©coupage pour les lignes et pour les colonnes. Dans ce cas, les blocs diagonaux sont Ã©galement des matrices carrÃ©es.

\Para{Proposition}

Soit $E$ un espace vectoriel de dimension finie $n$, $F$ un sous-espace vectoriel de $E$ et $uâˆˆ\LE$.
Soit $\B' = \nUplet e1p$ une base de $F$ telle que $\B = \nUplet e1n$ soit une base de $E$.
Soit $A$ la matrice de l'endomorphisme $u$ dans la base $\B$;
on la dÃ©compose par blocs selon le dÃ©coupage $(p,n-p)$ pour les lignes et les colonnes:
\[ A = \Matrix{A_{1,1}, A_{1,2}; A_{2,1}, A_{2,2}}. \]
Alors $F$ est stable par $u$ si et seulement si ma matrice $A_{2,1}$ est nulle.
Dans ce cas, notons $v$ l'endomophisme induit par $u$ sur $F$.
La matrice de $v$ dans la base $\B'$ est $A_{1,1}$.

% ---------------------------------------------------------------------------
\subsection{DÃ©terminants par blocs}

\Para{Attention}

Si $A$, $B$, $C$ et $D$ sont des matrices de $\MnK$ et si
$M = \begin{pmatrix} A & B \\ C & D \end{pmatrix} âˆˆ\mathrm{M}_{2n}(ğ•‚)$, alors en gÃ©nÃ©ral
\[ \det(M) â‰ \det(AD-BC). \]

\Para{ThÃ©orÃ¨me}[dÃ©terminant triangulaire par blocs]

Soit $Aâˆˆ\MnK$ une matrice carrÃ©e admettant une dÃ©composition par blocs suivant le dÃ©coupage $\nUplet n1s$ pour les lignes et pour les colonnes.
On note $A = \bigl( A_{i,j} \bigr)_{1â‰¤i,jâ‰¤s}$ cette dÃ©composition, de sorte que $A_{i,j}âˆˆ\mathrm{M}_{n_i,n_j}(ğ•‚)$.
On suppose que $A$ est triangulaire supÃ©rieure par blocs, Â£cad. que
\[ âˆ€(i,j)âˆˆ\Dcro{1,s}^2 \+ i > j \implies A_{i,j} = 0. \]

Alors le dÃ©terminant de $A$ est Ã©gal au produit des dÃ©terminants des blocs diagonaux:
\[ \det(A) = âˆ_{k=1}^s \det(A_{k,k}). \]

Le rÃ©sultat est identique dans le cas des matrices triangulaires infÃ©rieures par blocs.

% ---------------------------------------------------------------------------
\section{Divers}

\subsection{PolynÃ´me de matrice}

\Para{DÃ©finition}

Soit $Aâˆˆ\MnK$ une matrice carrÃ©e.
On dÃ©finit par rÃ©currence $A^n$ pour $nâˆˆâ„•$ par
$A^0 = I_n$ et $âˆ€nâˆˆâ„•$, $A^{n+1} = AÃ—A^n$.

Pour $P = âˆ‘_{k=0}^d a_k X^k$, on pose $P(A) = âˆ‘_{k=0}^d a_k A^k$.

\Para{Proposition}

Soit $E$ un $ğ•‚$-espace vectoriel de dimension finie, $\B$ une base de $E$, $uâˆˆ\LE$,
$A = \Mat_\B(u)$ et $Pâˆˆğ•‚[X]$.

Alors $\Mat_\B P(u) = P(A)$.

\Para{Corollaire}

Soit $Aâˆˆ\MnK$.
L'application \[ \Fonction{Ï•_A}{ğ•‚[X]}{\MnK}{P}{P(A)} \]
est Ã©galement un morphisme d'algÃ¨bre.
Autrement dit, si $P$ et $Q$ sont deux polynÃ´mes et $Î»$ un scalaire, on a
\begin{enumerate}
\item $(Î»P)(A) = Î»P(A)$
\item $(P+Q)(A) = P(A) + Q(A)$
\item $(PQ)(A) = P(A)Ã—Q(A)$
\end{enumerate}

\Para{Proposition}

Soit $Aâˆˆ\MnK$, $Qâˆˆ\GLnK$ et $Pâˆˆğ•‚[X]$.
Alors
\[ P \bigl( Q^{-1}AQ \bigr) = Q^{-1} \, P(A) \, Q. \]

% ---------------------------------------------------------------------------
\section{Exercices}

\Exercice

Soit $E = â„_3[X]$ et $\B$ la base canonique.
Soit $fâˆˆ\LE$ dÃ©fini par $f(P) = P(X+1)$.
\begin{enumerate}
\item DÃ©terminer $A = \Mat_\B f$.
\item Montrer que $A$ est inversible et calculer $A^{-1}$.
\item Reprendre les questions prÃ©cÃ©dentes pour $E=â„_n[X]$.
\end{enumerate}

\Exercice

Soit $A = \begin{pmatrix} -2 & 1 & 1 \\ 8 & 1 & -5 \\ 4 & 3 & -3 \end{pmatrix}$
et $C = \begin{pmatrix} 1 & 2 & -1 \\ 2 & -1 & -1 \\ -5 & 0 & 3 \end{pmatrix}$.

Existe-t-il une matrice $B$ telle que $A=BC$?

\Exercice

Soit $E$ un $ğ•‚$-Â£evdf. tel que $fâ—¦f = -\Id_E$.
Montrer qu'il existe une base $\B$ telle que la matrice de $f$ dans cette base soit diagonale par blocs, de la forme $\Mat_\B f = \mathrm{diag}(A,A,\dots,A)$ oÃ¹ $A = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$.

\Exercice[matrices Ã  diagonale dominante]

Soit $Aâˆˆ\MnC$ telle que
\[ âˆ€iâˆˆ\Dcro{1,n} \+ âˆ‘_{\substack{1â‰¤jâ‰¤n \\ jâ‰ i}} \Abs{a_{i,j}} < \Abs{a_{i,i}}. \]
Montrer que $A$ est inversible. On pourra montrer que $\Ker A = \Acco{0}$.

\Exercice

Soit $aâˆˆâ„$.
Pour $nâˆˆâ„•^*$, on dÃ©finit le dÃ©terminant d'ordre $n$
\[ Î”_n = \begin{vmatrix}
    a &  1 &  0 &  \cdots &  0  \\
    1 &  a &  1 &  \ddots &  \vdots  \\
    0 &  1 &  a &  \ddots &  0  \\
    \vdots &  \ddots &  \ddots &  \ddots &  1  \\
0 &  \cdots &  0 &  1 &  a \end{vmatrix} \]
\begin{enumerate}
\item DÃ©terminer une relation de rÃ©currence linÃ©aire d'ordre 2 vÃ©rifiÃ©e par la suite $(Î”_n)$.
\item On suppose $a = 2\cosÎ¸$ oÃ¹ $Î¸âˆˆ\intO{0,Ï€}$.
  Montrer que \[ Î”_n = \frac{\sin\bigl((n+1)Î¸\bigr)}{\sinÎ¸}. \]
\end{enumerate}

\Exercice

Soit $Aâˆˆ\MnC$. On pose
\[ \Fonction{Ï†}{\MnC}{\MnC}{M}{-M + \Tr(M)A.} \]
\begin{enumerate}
\item Montrer que $Ï†$ est un endomorphisme de $\MnC$.
\item Ã€ quelle condition $Ï†$ est-il un isomorphisme?
\item Soit $Bâˆˆ\MnC$.
  DÃ©terminer l'ensemble des solutions de l'Ã©quation $Ï†(M)=B$.
\end{enumerate}

\Exercice

Soit $A$, $B$, $C$, $D$ des matrices carrÃ©es de $\MnK$.
On suppose que $CD = DC$ et que $D$ est inversible.
\begin{enumerate}
\item
  En considÃ©rant le produit par blocs
  \[ \Matrix{I_n,-BD^{-1};0,I_n} \Matrix{A,B;C,D} \]
  montrer que
  \[ \det \Matrix{A,B;C,D} = \det(AD-BC). \]
\item Montrer que cette derniÃ¨re formule est encore vraie si l'on ne suppose plus que $D$ est inversible.
\item Trouver un contre-exemple si l'on ne suppose plus que $C$ et $D$ commutent.
\end{enumerate}

\end{document}
